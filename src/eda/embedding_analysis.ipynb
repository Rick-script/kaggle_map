{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "df = pd.read_csv(\"../../kaggle/input/map-charting-student-math-misunderstandings/train.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target列の作成\n",
    "df.Misconception = df.Misconception.fillna(\"NA\")\n",
    "df[\"target\"] = df.Category + \":\" + df.Misconception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 重複データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重複データの抽出\n",
    "duplicated_df = df[df.duplicated(subset=[\"QuestionId\", \"MC_Answer\", \"StudentExplanation\"], keep=False)].sort_values(by=[\"QuestionId\", \"MC_Answer\"])\n",
    "print(duplicated_df.shape)\n",
    "\n",
    "# Categoryが異なるデータを抽出\n",
    "conflict_df = duplicated_df.groupby([\"QuestionId\", \"MC_Answer\", \"StudentExplanation\"]).filter(lambda x: x[\"target\"].nunique() > 1)\n",
    "conflict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuestionIdのデータ数に対する割合\n",
    "all_count = df[\"QuestionId\"].value_counts().to_frame().reset_index()\n",
    "conflict_count = conflict_df[\"QuestionId\"].value_counts().to_frame().reset_index()\n",
    "merged_count = all_count.merge(conflict_count, on=\"QuestionId\", how=\"left\", suffixes=(\"_all\", \"_conflict\"))\n",
    "merged_count[\"conflict_ratio\"] = merged_count[\"count_conflict\"] / merged_count[\"count_all\"]\n",
    "merged_count = merged_count.fillna(0)\n",
    "merged_count.sort_values(by=\"conflict_ratio\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_df.to_csv(\"../../output/conflict_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 回答選択肢ごとの値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdの表示文字列\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回答の選択肢ごとのtargetのunique値\n",
    "groupby_df =df.groupby([\"QuestionId\", \"MC_Answer\"]).agg({\"MC_Answer\": \"size\", \"Misconception\": [\"nunique\",\"unique\"]}).reset_index()\n",
    "groupby_df.columns = [\"QuestionId\", \"MC_Answer\", \"count\", \"misconception_nunique\", \"misconception_unique\"]\n",
    "groupby_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Embeddingの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddingデータの読み込み\n",
    "similarity_matrix = np.load(\"similarity_matrix.npy\")\n",
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類似度行列から直接top3の同一QuestionId・MC_Answerデータを取得してデータフレームに追加\n",
    "def add_filtered_top_similarities(df, similarity_matrix, top_n=3):\n",
    "    \"\"\"類似度行列から同一QuestionId・MC_Answerの上位N件を取得してデータフレームに追加\"\"\"\n",
    "    \n",
    "    # 結果を格納する列を初期化\n",
    "    for i in range(1, top_n + 1):\n",
    "        df[f\"top{i}_row_id\"] = None\n",
    "        df[f\"top{i}_student_explanation\"] = None\n",
    "        df[f\"top{i}_target\"] = None\n",
    "        df[f\"top{i}_similarity_score\"] = None\n",
    "    \n",
    "    n_samples = len(df)\n",
    "    \n",
    "    for idx in range(n_samples):\n",
    "        current_row = df.iloc[idx]\n",
    "        question_id = current_row[\"QuestionId\"]\n",
    "        mc_answer = current_row[\"MC_Answer\"]\n",
    "        \n",
    "        # 現在の行の類似度を取得\n",
    "        similarities = similarity_matrix[idx]\n",
    "        # 自分自身を除外\n",
    "        similarities_copy = similarities.copy()\n",
    "        similarities_copy[idx] = -1\n",
    "        \n",
    "        # 類似度の高い順にソート\n",
    "        sorted_indices = np.argsort(similarities_copy)[::-1]\n",
    "        \n",
    "        valid_count = 0\n",
    "        \n",
    "        # 上位から順に同一QuestionId・MC_Answerをチェック\n",
    "        for sim_idx in sorted_indices:\n",
    "            if valid_count >= top_n:\n",
    "                break\n",
    "                \n",
    "            sim_row = df.iloc[sim_idx]\n",
    "            \n",
    "            # 同一QuestionId・MC_Answerかチェック\n",
    "            if (sim_row[\"QuestionId\"] == question_id and \n",
    "                sim_row[\"MC_Answer\"] == mc_answer):\n",
    "                \n",
    "                valid_count += 1\n",
    "                similarity_score = similarities_copy[sim_idx]\n",
    "                \n",
    "                # データフレームに直接追加\n",
    "                df.iloc[idx, df.columns.get_loc(f\"top{valid_count}_row_id\")] = sim_row[\"row_id\"]\n",
    "                df.iloc[idx, df.columns.get_loc(f\"top{valid_count}_student_explanation\")] = sim_row[\"StudentExplanation\"]\n",
    "                df.iloc[idx, df.columns.get_loc(f\"top{valid_count}_target\")] = sim_row[\"target\"]\n",
    "                df.iloc[idx, df.columns.get_loc(f\"top{valid_count}_similarity_score\")] = similarity_score\n",
    "    \n",
    "    return df\n",
    "\n",
    "# データフレームをコピーして処理\n",
    "df_with_filtered_similarity = df.copy()\n",
    "\n",
    "# 直接フィルタリングしながら類似度情報を追加\n",
    "df_with_filtered_similarity = add_filtered_top_similarities(df_with_filtered_similarity, similarity_matrix, top_n=3)\n",
    "\n",
    "print(\"処理後のデータフレーム形状:\", df_with_filtered_similarity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を確認\n",
    "df_with_filtered_similarity.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1, top2, top3の各条件での分析\n",
    "def analyze_target_consistency(df, condition_name, filter_condition):\n",
    "    \"\"\"指定された条件でフィルタして一致率を分析\"\"\"\n",
    "    filtered_df = df[filter_condition].copy()\n",
    "    \n",
    "    print(f\"\\n=== {condition_name} ===\")\n",
    "    print(f\"元データ数: {len(df)}\")\n",
    "    print(f\"フィルタ後データ数: {len(filtered_df)}\")\n",
    "    \n",
    "    if len(filtered_df) == 0:\n",
    "        print(\"データが存在しません\")\n",
    "        return None\n",
    "    \n",
    "    # 一致率の計算\n",
    "    filtered_df[\"target_match\"] = (filtered_df[\"target\"] == filtered_df[\"top1_target\"])\n",
    "    \n",
    "    # 類似度スコアを細かい範囲でグループ化\n",
    "    filtered_df[\"similarity_range\"] = pd.cut(\n",
    "        filtered_df[\"top1_similarity_score\"], \n",
    "        bins=[0, 0.5, 0.7, 0.8, 0.85, 0.90, 0.92, 0.94, 0.96, 0.98, 0.99, 1.0], \n",
    "        labels=[\"0.0-0.5\", \"0.5-0.7\", \"0.7-0.8\", \"0.8-0.85\", \"0.85-0.90\", \"0.90-0.92\", \"0.92-0.94\", \"0.94-0.96\", \"0.96-0.98\", \"0.98-0.99\", \"0.99-1.0\"]\n",
    "    )\n",
    "    \n",
    "    # 類似度範囲別の一致率を計算\n",
    "    match_rate = filtered_df.groupby(\"similarity_range\", observed=False).agg({\n",
    "        \"target_match\": [\"count\", \"sum\", \"mean\"],\n",
    "    }).round(4)\n",
    "\n",
    "    match_rate.columns = [\"total_count\", \"match_count\", \"match_rate\"]\n",
    "    display(match_rate)\n",
    "    \n",
    "    return match_rate\n",
    "\n",
    "# 各条件での分析実行\n",
    "# top1_target\n",
    "condition0 = df_with_filtered_similarity[\"top1_target\"] == df_with_filtered_similarity[\"top1_target\"]\n",
    "result0 = analyze_target_consistency(df_with_filtered_similarity, \"top1_target == top1_target\", condition0)\n",
    "\n",
    "# 条件1: top1_target == top2_target\n",
    "condition1 = df_with_filtered_similarity[\"top1_target\"] == df_with_filtered_similarity[\"top2_target\"]\n",
    "result1 = analyze_target_consistency(df_with_filtered_similarity, \"top1_target == top2_target\", condition1)\n",
    "\n",
    "# 条件2: top1_target == top2_target == top3_target\n",
    "condition2 = (df_with_filtered_similarity[\"top1_target\"] == df_with_filtered_similarity[\"top2_target\"]) & \\\n",
    "             (df_with_filtered_similarity[\"top2_target\"] == df_with_filtered_similarity[\"top3_target\"])\n",
    "result2 = analyze_target_consistency(df_with_filtered_similarity, \"top1_target == top2_target == top3_target\", condition2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1~top2が同一かつ平均スコアが閾値以上という条件での分析\n",
    "def analyze_with_avg_score_threshold(df, threshold_list=[0.9, 0.92, 0.94, 0.96, 0.98]):\n",
    "    \"\"\"top1~top2が同一かつ平均スコアが閾値以上という条件で分析\"\"\"\n",
    "\n",
    "    # top1~top2が全て同一の条件\n",
    "    all_same_condition = (df[\"top1_target\"] == df[\"top2_target\"])\n",
    "    \n",
    "    # 平均スコアを計算\n",
    "    df_filtered = df[all_same_condition].copy()\n",
    "    df_filtered[\"avg_similarity_score\"] = (df_filtered[\"top1_similarity_score\"] + df_filtered[\"top2_similarity_score\"]) / 2\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for threshold in threshold_list:\n",
    "        # 閾値以上の条件\n",
    "        threshold_condition = df_filtered[\"avg_similarity_score\"] >= threshold\n",
    "        filtered_data = df_filtered[threshold_condition]\n",
    "        \n",
    "        if len(filtered_data) == 0:\n",
    "            print(f\"\\n閾値 {threshold}: データなし\")\n",
    "            continue\n",
    "            \n",
    "        # 一致率の計算\n",
    "        filtered_data = filtered_data.copy()\n",
    "        filtered_data[\"target_match\"] = (filtered_data[\"target\"] == filtered_data[\"top1_target\"])\n",
    "        \n",
    "        total_count = len(filtered_data)\n",
    "        match_count = filtered_data[\"target_match\"].sum()\n",
    "        match_rate = match_count / total_count\n",
    "        \n",
    "        avg_score = filtered_data[\"avg_similarity_score\"].mean()\n",
    "        \n",
    "        result = {\n",
    "            \"threshold\": threshold,\n",
    "            \"total_count\": total_count,\n",
    "            \"match_count\": match_count,\n",
    "            \"match_rate\": round(match_rate, 4),\n",
    "            \"avg_similarity_score\": round(avg_score, 4)\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 分析実行\n",
    "result_df = analyze_with_avg_score_threshold(df_with_filtered_similarity)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 予測データとの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測データの読み込み\n",
    "score_df = pd.read_csv(\"merged_predictions_with_fold.csv\")\n",
    "score_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_correctを取得してマージ\n",
    "score_result_df = score_df[[\"row_id\", \"is_correct\"]].sort_values(by=\"row_id\").reset_index(drop=True)\n",
    "df_with_filtered_similarity = df_with_filtered_similarity.merge(score_result_df, on=\"row_id\", how=\"left\")\n",
    "df_with_filtered_similarity.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1~top2が同一かつ平均スコアが閾値以上という条件での分析\n",
    "def analyze_with_avg_score_threshold(df, threshold_list=[0.9, 0.92, 0.94, 0.96, 0.98, 0.99]):\n",
    "    \"\"\"top1~top2が同一かつ平均スコアが閾値以上という条件で分析\"\"\"\n",
    "\n",
    "    # top1~top2が全て同一の条件\n",
    "    all_same_condition = (df[\"top1_target\"] == df[\"top1_target\"])\n",
    "    \n",
    "    # 平均スコアを計算\n",
    "    df_filtered = df[all_same_condition].copy()\n",
    "    df_filtered[\"avg_similarity_score\"] = (df_filtered[\"top1_similarity_score\"] + df_filtered[\"top1_similarity_score\"]) / 2\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for threshold in threshold_list:\n",
    "        # 閾値以上の条件\n",
    "        threshold_condition = df_filtered[\"avg_similarity_score\"] >= threshold\n",
    "        filtered_data = df_filtered[threshold_condition]\n",
    "        \n",
    "        if len(filtered_data) == 0:\n",
    "            print(f\"\\n閾値 {threshold}: データなし\")\n",
    "            continue\n",
    "            \n",
    "        # 一致率の計算\n",
    "        filtered_data = filtered_data.copy()\n",
    "        filtered_data[\"target_match\"] = (filtered_data[\"target\"] == filtered_data[\"top1_target\"])\n",
    "        \n",
    "        total_count = len(filtered_data)\n",
    "        match_count = filtered_data[\"target_match\"].sum()\n",
    "        match_rate = match_count / total_count\n",
    "        pred_count = filtered_data[\"is_correct\"].sum()\n",
    "        pred_rate = pred_count / total_count\n",
    "        \n",
    "        avg_score = filtered_data[\"avg_similarity_score\"].mean()\n",
    "        \n",
    "        result = {\n",
    "            \"threshold\": threshold,\n",
    "            \"total_count\": total_count,\n",
    "            \"match_count\": match_count,\n",
    "            \"match_rate\": round(match_rate, 4),\n",
    "            \"pred_rate\": round(pred_rate, 4),\n",
    "            \"avg_similarity_score\": round(avg_score, 4)\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 分析実行\n",
    "result_df = analyze_with_avg_score_threshold(df_with_filtered_similarity)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 予測データとembeddingラベルの不一致分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測とembeddingラベルの不一致データを抽出\n",
    "def analyze_prediction_embedding_mismatch(df, min_avg_similarity=0.99):\n",
    "    \"\"\"予測データとembeddingラベルの不一致を分析\"\"\"\n",
    "    \n",
    "    # top1とtop2が同一で高い類似度を持つデータをフィルタ\n",
    "    same_top_condition = (df[\"top1_target\"] == df[\"top1_target\"])\n",
    "    df_filtered = df[same_top_condition].copy()\n",
    "    \n",
    "    # 平均類似度を計算\n",
    "    df_filtered[\"avg_similarity_score\"] = (df_filtered[\"top1_similarity_score\"] + df_filtered[\"top1_similarity_score\"]) / 2\n",
    "    \n",
    "    # 類似度閾値でフィルタ\n",
    "    high_similarity_condition = df_filtered[\"avg_similarity_score\"] >= min_avg_similarity\n",
    "    df_high_sim = df_filtered[high_similarity_condition].copy()\n",
    "    \n",
    "    # embeddingベースのラベル（top1_target）とis_correctの一致・不一致を判定\n",
    "    df_high_sim[\"embedding_correct\"] = df_high_sim[\"target\"] == df_high_sim[\"top1_target\"]\n",
    "    df_high_sim[\"pred_embedding_match\"] = df_high_sim[\"is_correct\"] == df_high_sim[\"embedding_correct\"]\n",
    "    \n",
    "    print(f\"高類似度データ数（avg_similarity >= {min_avg_similarity}）: {len(df_high_sim)}\")\n",
    "    print(f\"予測とembeddingラベル一致数: {df_high_sim['pred_embedding_match'].sum()}\")\n",
    "    print(f\"予測とembeddingラベル不一致数: {(~df_high_sim['pred_embedding_match']).sum()}\")\n",
    "    print(f\"一致率: {df_high_sim['pred_embedding_match'].mean():.4f}\")\n",
    "    \n",
    "    # 不一致データを抽出\n",
    "    mismatch_data = df_high_sim[~df_high_sim[\"pred_embedding_match\"]].copy()\n",
    "    \n",
    "    return df_high_sim, mismatch_data\n",
    "\n",
    "# 分析実行\n",
    "df_analysis, mismatch_df = analyze_prediction_embedding_mismatch(df_with_filtered_similarity)\n",
    "print(f\"\\n不一致データ数: {len(mismatch_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不一致パターンの詳細分析\n",
    "def analyze_mismatch_patterns(mismatch_df):\n",
    "    \"\"\"不一致パターンを詳細分析\"\"\"\n",
    "    \n",
    "    print(\"=== 不一致パターン分析 ===\")\n",
    "    \n",
    "    # パターン1: 予測正解、embedding不正解\n",
    "    pred_correct_embed_wrong = mismatch_df[\n",
    "        (mismatch_df[\"is_correct\"] == True) & \n",
    "        (mismatch_df[\"embedding_correct\"] == False)\n",
    "    ]\n",
    "    \n",
    "    # パターン2: 予測不正解、embedding正解\n",
    "    pred_wrong_embed_correct = mismatch_df[\n",
    "        (mismatch_df[\"is_correct\"] == False) & \n",
    "        (mismatch_df[\"embedding_correct\"] == True)\n",
    "    ]\n",
    "    \n",
    "    print(f\"パターン1 (予測正解 & embedding不正解): {len(pred_correct_embed_wrong)}件\")\n",
    "    print(f\"パターン2 (予測不正解 & embedding正解): {len(pred_wrong_embed_correct)}件\")\n",
    "    \n",
    "    # ターゲット分布を確認\n",
    "    print(f\"\\n=== パターン1のターゲット分布 ===\")\n",
    "    if len(pred_correct_embed_wrong) > 0:\n",
    "        pattern1_target_dist = pred_correct_embed_wrong[\"target\"].value_counts()\n",
    "        print(pattern1_target_dist)\n",
    "    \n",
    "    print(f\"\\n=== パターン2のターゲット分布 ===\")\n",
    "    if len(pred_wrong_embed_correct) > 0:\n",
    "        pattern2_target_dist = pred_wrong_embed_correct[\"target\"].value_counts()\n",
    "        print(pattern2_target_dist)\n",
    "    \n",
    "    return pred_correct_embed_wrong, pred_wrong_embed_correct\n",
    "\n",
    "# パターン分析実行\n",
    "pattern1_df, pattern2_df = analyze_mismatch_patterns(mismatch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 具体的な不一致事例を確認\n",
    "def show_mismatch_examples(pattern_df, pattern_name, n_examples=5):\n",
    "    \"\"\"不一致事例を表示\"\"\"\n",
    "    \n",
    "    print(f\"\\n=== {pattern_name} 具体例 (上位{n_examples}件) ===\")\n",
    "    \n",
    "    if len(pattern_df) == 0:\n",
    "        print(\"該当データなし\")\n",
    "        return\n",
    "        \n",
    "    # 類似度の高い順にソート\n",
    "    sorted_df = pattern_df.sort_values(\"avg_similarity_score\", ascending=False).head(n_examples)\n",
    "    \n",
    "    for idx, row in sorted_df.iterrows():\n",
    "        print(f\"\\n--- 事例 {idx} ---\")\n",
    "        print(f\"QuestionId: {row['QuestionId']}\")\n",
    "        print(f\"MC_Answer: {row['MC_Answer']}\")\n",
    "        print(f\"StudentExplanation: {row['StudentExplanation']}\")\n",
    "        print(f\"実際のTarget: {row['target']}\")\n",
    "        print(f\"Top1 Target: {row['top1_target']}\")\n",
    "        print(f\"Top1 Explanation: {row['top1_student_explanation']}\")\n",
    "        print(f\"予測結果 (is_correct): {row['is_correct']}\")\n",
    "        print(f\"Embedding一致 (embedding_correct): {row['embedding_correct']}\")\n",
    "        print(f\"平均類似度: {row['avg_similarity_score']:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# パターン1の具体例\n",
    "show_mismatch_examples(pattern1_df, \"パターン1: 予測正解 & embedding不正解\")\n",
    "\n",
    "# パターン2の具体例  \n",
    "show_mismatch_examples(pattern2_df, \"パターン2: 予測不正解 & embedding正解\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 類似度0.98以上でラベルが異なるデータの抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 類似度0.98以上でラベルが異なるデータを抽出\n",
    "def extract_high_similarity_different_labels(df, similarity_threshold=0.98):\n",
    "    \"\"\"\n",
    "    類似度が閾値以上でラベルが異なるデータを抽出する\n",
    "    \"\"\"\n",
    "    \n",
    "    # 類似度が閾値以上のデータをフィルタ\n",
    "    high_similarity_condition = df[\"top1_similarity_score\"] >= similarity_threshold\n",
    "    high_sim_df = df[high_similarity_condition].copy()\n",
    "    \n",
    "    # ラベルが異なるデータをフィルタ\n",
    "    different_labels_condition = high_sim_df[\"target\"] != high_sim_df[\"top1_target\"]\n",
    "    different_labels_df = high_sim_df[different_labels_condition].copy()\n",
    "    \n",
    "    print(f\"類似度{similarity_threshold}以上のデータ数: {len(high_sim_df)}\")\n",
    "    print(f\"そのうちラベルが異なるデータ数: {len(different_labels_df)}\")\n",
    "    print(f\"異なるラベルの割合: {len(different_labels_df)/len(high_sim_df)*100:.2f}%\")\n",
    "    \n",
    "    return different_labels_df\n",
    "\n",
    "# データを抽出\n",
    "high_sim_diff_labels_df = extract_high_similarity_different_labels(df_with_filtered_similarity, 0.98)\n",
    "\n",
    "# データの内容を確認\n",
    "print(f\"\\n抽出されたデータの形状: {high_sim_diff_labels_df.shape}\")\n",
    "if len(high_sim_diff_labels_df) > 0:\n",
    "    print(f\"\\nラベルの組み合わせ:\")\n",
    "    label_combinations = high_sim_diff_labels_df[[\"target\", \"top1_target\"]].value_counts()\n",
    "    print(label_combinations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainデータフレーム形式で近しいレコードを順に並べて出力\n",
    "def create_paired_output(df, similarity_threshold=0.98):\n",
    "    \"\"\"\n",
    "    類似度が閾値以上でラベルが異なるデータペアを、trainデータフレーム形式で順に並べて出力\n",
    "    \"\"\"\n",
    "    \n",
    "    # 類似度が閾値以上でラベルが異なるデータを抽出\n",
    "    high_similarity_condition = df[\"top1_similarity_score\"] >= similarity_threshold\n",
    "    different_labels_condition = df[\"target\"] != df[\"top1_target\"]\n",
    "    \n",
    "    target_df = df[high_similarity_condition & different_labels_condition].copy()\n",
    "    \n",
    "    print(f\"類似度{similarity_threshold}以上でラベルが異なるデータ数: {len(target_df)}\")\n",
    "    \n",
    "    # 出力用のリストを作成\n",
    "    output_rows = []\n",
    "    processed_pairs = set()\n",
    "    \n",
    "    for idx, row in target_df.iterrows():\n",
    "        # ペアがすでに処理済みかチェック\n",
    "        pair_key = tuple(sorted([row[\"row_id\"], row[\"top1_row_id\"]]))\n",
    "        if pair_key in processed_pairs:\n",
    "            continue\n",
    "            \n",
    "        # 元のレコードを追加\n",
    "        original_record = df[df[\"row_id\"] == row[\"row_id\"]].iloc[0]\n",
    "        output_rows.append({\n",
    "            \"row_id\": original_record[\"row_id\"],\n",
    "            \"QuestionId\": original_record[\"QuestionId\"], \n",
    "            \"QuestionText\": original_record[\"QuestionText\"],\n",
    "            \"MC_Answer\": original_record[\"MC_Answer\"],\n",
    "            \"StudentExplanation\": original_record[\"StudentExplanation\"],\n",
    "            \"Category\": original_record[\"Category\"],\n",
    "            \"Misconception\": original_record[\"Misconception\"],\n",
    "            \"similarity_score\": row[\"top1_similarity_score\"],\n",
    "            \"pair_type\": \"original\"\n",
    "        })\n",
    "        \n",
    "        # 類似レコードを追加\n",
    "        similar_record = df[df[\"row_id\"] == row[\"top1_row_id\"]].iloc[0]\n",
    "        output_rows.append({\n",
    "            \"row_id\": similar_record[\"row_id\"],\n",
    "            \"QuestionId\": similar_record[\"QuestionId\"],\n",
    "            \"QuestionText\": similar_record[\"QuestionText\"], \n",
    "            \"MC_Answer\": similar_record[\"MC_Answer\"],\n",
    "            \"StudentExplanation\": similar_record[\"StudentExplanation\"],\n",
    "            \"Category\": similar_record[\"Category\"],\n",
    "            \"Misconception\": similar_record[\"Misconception\"],\n",
    "            \"similarity_score\": row[\"top1_similarity_score\"],\n",
    "            \"pair_type\": \"similar\"\n",
    "        })\n",
    "        \n",
    "        # 処理済みペアに追加\n",
    "        processed_pairs.add(pair_key)\n",
    "    \n",
    "    # データフレームに変換\n",
    "    output_df = pd.DataFrame(output_rows)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# ペア形式のデータを作成\n",
    "paired_output_df = create_paired_output(df_with_filtered_similarity, 0.98)\n",
    "\n",
    "# ファイル名\n",
    "output_filename = \"../../output/paired_high_similarity_different_labels_0.98.csv\"\n",
    "\n",
    "# CSVファイルとして出力\n",
    "paired_output_df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"CSVファイルを出力しました: {output_filename}\")\n",
    "print(f\"出力データ数: {len(paired_output_df)}\")\n",
    "print(f\"ペア数: {len(paired_output_df)//2}\")\n",
    "\n",
    "# サンプルデータを表示\n",
    "if len(paired_output_df) > 0:\n",
    "    print(f\"\\n--- サンプルデータ (最初の1ペア) ---\")\n",
    "    for i in range(0, min(4, len(paired_output_df)), 2):\n",
    "        print(f\"\\n=== ペア {i//2 + 1} (類似度: {paired_output_df.iloc[i]['  _score']:.4f}) ===\")\n",
    "        \n",
    "        # 元のレコード\n",
    "        orig = paired_output_df.iloc[i]\n",
    "        print(f\"[元レコード] row_id: {orig['row_id']}\")\n",
    "        print(f\"StudentExplanation: {orig['StudentExplanation']}\")\n",
    "        print(f\"Category: {orig['Category']}, Misconception: {orig['Misconception']}\")\n",
    "        \n",
    "        # 類似レコード\n",
    "        sim = paired_output_df.iloc[i+1]\n",
    "        print(f\"[類似レコード] row_id: {sim['row_id']}\")\n",
    "        print(f\"StudentExplanation: {sim['StudentExplanation']}\")\n",
    "        print(f\"Category: {sim['Category']}, Misconception: {sim['Misconception']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
