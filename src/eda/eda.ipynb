{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train = pd.read_csv(\"../../kaggle/input/map-charting-student-math-misunderstandings/train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QuestionTextの確認\n",
    "print(train[\"QuestionText\"].nunique())\n",
    "print(train[\"QuestionText\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categoryの確認\n",
    "print(train[\"Category\"].nunique(dropna=False))\n",
    "print(train[\"Category\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "- True_Correct\n",
    "  - 意味: 生徒の説明は論理的に正しく、正しい答えと一致しています (例: 正しい推論と正しい計算)。\n",
    "  - 例: 生徒が 3/9 を 1/3 に正しく簡略化し、明確に説明します。\n",
    "\n",
    "- True_Neither\n",
    "  - 意味: 生徒の説明は、明確に正しいか間違っているわけではなく、漠然としていたり​​関連性がなかったりするかもしれませんが、誤解は含まれていません。\n",
    "  - 例: 生徒が理由も述べずに「それが私の理解したことです」と答えた場合、これは役に立ちませんが、間違いではありません。\n",
    "\n",
    "- True_Misconception\n",
    "  - 意味: 生徒は正しい答えを得ましたが、間違った理由で、誤解していることを示しています。\n",
    "  - 例: 生徒は正解にたどり着きましたが、それは 3 つの部分が塗りつぶされていないのではなく 3 つの部分が塗りつぶされているからだと解釈しました。\n",
    "\n",
    "- False_Neither\n",
    "  - 意味: 答えは正しくなく、説明も曖昧または役に立たないが、明らかな誤解に基づいているわけではない。\n",
    "  - 例: 生徒が、間違いの原因を説明しない、主題から外れた内容や数学的でない内容を書きます。\n",
    "\n",
    "- False_Misconception\n",
    "  - 意味: 回答は誤りであり、説明には特定の識別可能な誤解が示されています。\n",
    "  - 例: 生徒は、9 個のうち 3 個が塗りつぶされているので (質問では塗りつぶされていないものを尋ねているのに)、9 個のうち 3 個が答えであると述べており、尋ねられていることを誤解しています。\n",
    "\n",
    "- False_Correct\n",
    "  - 意味: 生徒は間違った答えを出していますが、説明は正しいです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misconceptionの確認\n",
    "print(train[\"Misconception\"].nunique(dropna=False))\n",
    "print(train[\"Misconception\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StudentExplanationの確認\n",
    "print(train[\"StudentExplanation\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = train[\"QuestionText\"].unique()\n",
    "\n",
    "for text in text_list:\n",
    "    tmp = train[train[\"QuestionText\"] == text]\n",
    "    print(text)\n",
    "    display(tmp.groupby(\"MC_Answer\")[[\"Category\", \"Misconception\"]].value_counts(dropna=False).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 不可解なデータの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Wrong_Fraction と Wrong_fraction の意味は同じ異なるMisconceptionが存在する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = train[train[\"Misconception\"] == \"Wrong_Fraction\"]\n",
    "tmp2 = train[train[\"Misconception\"] == \"Wrong_fraction\"]\n",
    "print(tmp1.shape)\n",
    "display(tmp1.head(2))\n",
    "print(tmp2.shape)\n",
    "display(tmp2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Wrong_Fraction: {tmp1['QuestionId'].unique()}\")\n",
    "print(f\"Wrong_fraction: {tmp2['QuestionId'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "問題が違うので前処理で統一して、後処理で分岐させるやり方で良いかもしれない  \n",
    "というか意味が分かりづらいMisconceptionも多くあるので、対応表を作るのもありかも"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### WNB と Whole_numbers_larger も同じカテゴリなのでは疑惑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = train[train[\"Misconception\"] == \"WNB\"]\n",
    "tmp2 = train[train[\"Misconception\"] == \"Whole_numbers_larger\"]\n",
    "print(tmp1.shape)\n",
    "display(tmp1.head(2))\n",
    "print(tmp2.shape)\n",
    "display(tmp2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"WNB: {tmp1['QuestionId'].unique()}\")\n",
    "print(f\"Whole_numbers_larger: {tmp2['QuestionId'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シャッフル\n",
    "tmp1 = tmp1.sample(frac=1).reset_index(drop=True)\n",
    "tmp2 = tmp2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "for i in range(10):\n",
    "    print(tmp1.iloc[i][\"QuestionText\"])\n",
    "    print(tmp1.iloc[i][\"MC_Answer\"])\n",
    "    print(tmp1.iloc[i][\"Category\"])\n",
    "    print(tmp1.iloc[i][\"StudentExplanation\"])\n",
    "    print(tmp1.iloc[i][\"Misconception\"])\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "for i in range(10):\n",
    "    print(tmp2.iloc[i][\"QuestionText\"])\n",
    "    print(tmp2.iloc[i][\"MC_Answer\"])\n",
    "    print(tmp2.iloc[i][\"Category\"])\n",
    "    print(tmp2.iloc[i][\"StudentExplanation\"])\n",
    "    print(tmp2.iloc[i][\"Misconception\"])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "1. WNB\n",
    "これは \"Wrong Number of Both\"（または \"Wrong numerator/denominator balance\" のような略語）として使われているケースが多いです。  \n",
    "与えられた分数の分母・分子を正しく数えていない、あるいは全体と一部の関係を誤解しているときに付けられているラベルです。  \n",
    "例：「9個に分かれているのに、6と3を別々にして3/6と答える」→ WNB。  \n",
    "つまり「全体の数え方を間違えている」誤答に対応します。\n",
    "\n",
    "2. Whole_numbers_larger\n",
    "こちらは「小数や分数よりも整数（whole number）の方が大きい」と誤解しているケースに付けられています。  \n",
    "例：「どの数が大きいか？」で 6, 0.8, 0.75 があった場合に「6は整数だから一番大きい」と誤解する。  \n",
    "これは「数の大小関係の誤概念」に関するラベルです。\n",
    "\n",
    "3. 違いのまとめ\n",
    "WNB → 「分数の分母・分子の扱いを誤っている（全体と部分の数え間違い）」  \n",
    "Whole_numbers_larger → 「整数の方が常に小数より大きいと誤解している」  \n",
    "したがって、両者は別の誤答カテゴリーであり、同じ意味ではありません。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 特定の問題でラベル付与が間違えている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [12518, 12878, 14273, 14280, 14305, 14418]\n",
    "train[train[\"row_id\"].isin(id_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "12787はTrueの回答、14280,14305,14418はFalseの回答のはず"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18個のラベル付与が間違えている\n",
    "tmp = train.copy()\n",
    "tmp = tmp[tmp[\"QuestionId\"] == 31778]\n",
    "tmp[\"Correct\"] = tmp[\"Category\"].str.startswith(\"True\")\n",
    "display(tmp[(tmp[\"MC_Answer\"] == r\"\\( 6 \\)\") & (tmp[\"Correct\"] == False)])\n",
    "display(tmp[(tmp[\"MC_Answer\"] != r\"\\( 6 \\)\") & (tmp[\"Correct\"] == True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# シャッフル\n",
    "id_list = [\n",
    "    12878,\n",
    "    12901,\n",
    "    13876,\n",
    "    14089,\n",
    "    14159,\n",
    "    14185,\n",
    "    14280,\n",
    "    14305,\n",
    "    14321,\n",
    "    14335,\n",
    "    14338,\n",
    "    14352,\n",
    "    14355,\n",
    "    14403,\n",
    "    14407,\n",
    "    14412,\n",
    "    14413,\n",
    "    14418,\n",
    "]\n",
    "tmp1 = train[train[\"row_id\"].isin(id_list)]\n",
    "tmp2 = train[train[\"QuestionId\"] == 31778]\n",
    "tmp1 = tmp1.sample(frac=1).reset_index(drop=True)\n",
    "tmp2 = tmp2.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"ラベル付与誤りあり\")\n",
    "for i in range(16):\n",
    "    print(tmp1.iloc[i][\"QuestionText\"])\n",
    "    print(tmp1.iloc[i][\"MC_Answer\"])\n",
    "    print(tmp1.iloc[i][\"Category\"])\n",
    "    print(tmp1.iloc[i][\"StudentExplanation\"])\n",
    "    print(tmp1.iloc[i][\"Misconception\"])\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nラベル付与誤りなし\")\n",
    "for i in range(100):\n",
    "    print(tmp2.iloc[i][\"QuestionText\"])\n",
    "    print(tmp2.iloc[i][\"MC_Answer\"])\n",
    "    print(tmp2.iloc[i][\"Category\"])\n",
    "    print(tmp2.iloc[i][\"StudentExplanation\"])\n",
    "    print(tmp2.iloc[i][\"Misconception\"])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "ラベル付与が誤ってしまった主な理由\n",
    "考えられる誤りの原因は、主に以下の3つのパターンに分類できます。\n",
    "\n",
    "1. 「解答」と「理由」の評価の混同  \n",
    "これが最も多い誤りのパターンだと考えられます。生徒が書いた「理由」には正しい答えや計算過程が含まれているにもかかわらず、選択した「解答」そのものが間違っているケースです。  \n",
    "具体例:  \n",
    "解答: 9  \n",
    "ラベル: True_Correct  \n",
    "理由: I divided 9/15 by 3, then got 3/5 and timsed it by 2 and got 6/10.  \n",
    "この例では、生徒は理由の中で「6/10」という正しい答えを導き出しています。しかし、最終的に選択した「解答」は「9」で、これは間違いです。  \n",
    "誤りのきっかけ:  \n",
    "ラベルを付与した担当者が、生徒が書いた理由の正しさに注目しすぎて、「思考プロセスは正しい (Correct)」そして「（プロセスが正しいから）正解 (True)」と判断してしまった可能性があります。本来は、まず「解答」が間違っているので「False」に分類すべきところです。  \n",
    "\n",
    "2. 正解・不正解の単純な判断ミス  \n",
    "明らかな正解を「False（不正解）」としたり、不正解を「True（正解）」としたりしているケースです。  \n",
    "具体例:  \n",
    "解答: 6  \n",
    "ラベル: False_Neither  \n",
    "理由: i worked it out on my white board  \n",
    "この問題の正しい答えは 6 です。解答は合っているにもかかわらず、ラベルは「False（不正解）」となっています。  \n",
    "誤りのきっかけ:  \n",
    "これは、単純な見間違いやクリックミスといったヒューマンエラーである可能性が最も高いです。特に理由が書かれていない場合などに、誤って不正解と判断してしまったのかもしれません。  \n",
    "\n",
    "3. 複雑な理由の解釈による判断の揺れ  \n",
    "生徒の理由が支離滅裂であったり、部分的にしか合っていなかったりする場合、評価者の解釈が難しくなり、結果として不適切なラベルが付いてしまうことがあります。  \n",
    "具体例:  \n",
    "解答: 9  \n",
    "ラベル: True_Neither  \n",
    "理由: Because 10 is 2 / 3 of 15, and 2 is 6.  \n",
    "この理由では、正しい答えである「6」という数字が出てきますが、それがなぜ解答の「9」に結びつくのか不明です。評価者が「正しい数字に言及している」という点だけを見て、不正解であるにもかかわらず「True」と付けてしまった可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### ラベル付与誤りの要因分析表\n",
    "\n",
    "| # | 解答 | ラベル | 理由 | 分析と割り当て要因 |\n",
    "| :-- | :--- | :--- | :--- | :--- |\n",
    "| 1 | `9` | True\\_Correct | `i think this is because 9/15=18/30 and 6/10 =18-30.` | **要因1**: 解答は不正解だが、理由に正しい計算過程が含まれているため、理由を評価して`True`と判断してしまった。 |\n",
    "| 2 | `9` | True\\_Correct | `It is six because they are both equal to 3over5.` | **要因1**: 理由の中で「答えは6」と明言しており、解答の選択ミスを無視して理由の正しさを評価した典型例。 |\n",
    "| 3 | `6` | False\\_Neither | `m'y dad andave i bothe guessed... i wasn't ' t sur how that woulld work...` | **要因1**: 解答は正解だが、理由が「自信がない」という内容のため、理解度を低く見積もり`False`と評価した可能性が高い。 |\n",
    "| 4 | `6` | False\\_Neither | `Because when I work is out with rthe bar methood che awser comed up with 9.` | **要因1**: 解答は正解（6）だが、理由では「答えは9になった」と述べている。この間違った理由を評価し`False`とした。 |\n",
    "| 5 | `6` | False\\_Neither | `i worked it out on my white board` | **要因2**: 解答は正解だが`False`になっている。理由に判断材料がないため、単純な正誤の判断ミスと考えられる。 |\n",
    "| 6 | `6` | False\\_Neither | `Because on the second fraction it has a 9.` | **要因1**: 解答は正解だが、理由が的を射ていないため、思考プロセスが誤っていると判断し`False`とした可能性。 |\n",
    "| 7 | `9` | True\\_Correct | `To get a denominator of 10, we need to divide by 3 and multiply by 2. Then, 9/15=3/5=6/10, so A = 6.` | **要因1**: 理由が完璧に正しく「A = 6」と結論付けているため、解答の選択ミスを見逃し、理由だけを評価した例。 |\n",
    "| 8 | `9` | True\\_Correct | `I divided 9/15 by 3, then got 3/5 and timsed it by 2 and got 6/10.` | **要因1**: 解答は不正解だが、理由の中で正しい答え「6/10」を導いているため、理由の正しさを評価してしまった。 |\n",
    "| 9 | `6` | False\\_Neither | `tha answear is d becase yoy can ' t simplify 9.` | **要因1**: 解答は正解だが、理由が誤っているため、思考プロセスを重視して`False`と評価したと考えられる。 |\n",
    "| 10 | `9` | True\\_Neither | `Il believe that is the ansewer because I calculatted iti.` | **要因2**: 解答は不正解だが`True`になっている。理由に判断材料がないため、単純な正誤の判断ミスと考えられる。 |\n",
    "| 11 | `9` | True\\_Neither | `if you simplify it to 3/5 then you get 9/15.` | **要因1**: 解答は不正解だが、理由に「3/5に単純化する」という正しいプロセスが含まれるため、それを評価した可能性。 |\n",
    "| 12 | `9` | True\\_Correct | `I think it's C because 6/10 is the same as 9/15.` | **要因1**: 理由の中で正しい答え（C=6）と、その根拠を明確に述べているため、解答の選択ミスを無視して理由を評価した。 |\n",
    "| 13 | `9` | True\\_Neither | `You have to change the denominator to 150 then you will get the answer.` | **要因1**: 解答は不正解だが、理由が有効な解法アプローチに言及しているため、その点を評価してしまった可能性。 |\n",
    "| 14 | `9` | True\\_Neither | `since 9 - 3 = 6h are so i't must be these ohne!` | **要因3**: 理由は支離滅裂だが、偶然正しい答えの数字「6」を含む。この数字に評価者が混乱し、不適切な判断をした可能性。 |\n",
    "| 15 | `9` | True\\_Correct | `so the common denominator is 30 and the product of 15x2=30... therefore, a=6.` | **要因1**: 理由が非常に詳細かつ正確に「a=6」と結論付けている。解答の選択ミスより、この完璧な理由を優先して評価した例。 |\n",
    "| 16 | `6` | False\\_Neither | `becose thirty tope number is a nine.` | **要因1**: 解答は正解だが、理由が全く意味をなしていない。この誤った（無意味な）理由を評価し`False`とした。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "割と回答理由だけを見て正誤評価を下していそうな問題がちらほら。おそらくテストデータにもこのようなミスが入っているはずなので、ここらへんをうまく盛り込められれば上位に食い込めるかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 同じ回答根拠なのに付与されるカテゴリが異なる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train[\"StudentExplanation\"] == \"Because there are 9 triangles and 3 of them are not shaded\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "上がcorrectなのであれば、下はFalse_Correctが妥当なはず  \n",
    "ここらへんの説明付ができるとよいか難しそう。LLMの理解力に任せるか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-map",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
