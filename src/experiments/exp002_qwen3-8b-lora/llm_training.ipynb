{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 4247,
     "status": "error",
     "timestamp": 1758799522026,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "998f0e04",
    "outputId": "e6fe016c-505a-4e97-ee09-c79f85435dc7"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp002_qwen3-8b-lora\n",
    "\n",
    "    !pip install -q trl==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "8d16216d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "9c3d4b52"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp002_qwen3-8b-lora\"\n",
    "    model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    output_dir_path = \"output/\"\n",
    "    log_dir_path = \"logs/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 2\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 5e-4\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 64\n",
    "    lora_alpha = 128\n",
    "    lora_dropout = 0.01\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = \"all-linear\"\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\"]\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"You are a specialist in identifying the types of misunderstandings that arise from students' answers to math problems.\n",
    "Based on the information provided below, please determine what kind of misunderstanding the student has.\n",
    "\n",
    "Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "513676b3"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "bc7a98ad"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "5b46ca05"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "a9d252ef"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "c7626f3a"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"Category\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"Category\"].str.replace(\"False\", \"True\"),\n",
    "        df[\"Category\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"Category\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"Category\"].str.replace(\"True\", \"False\"),\n",
    "        df[\"Category\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "b3777e95"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1758248202177,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "23c3d5ca",
    "outputId": "96f2a618-9041-4810-c599-05ede2fcf290"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "f1b0f41e"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "9d534d23"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f966251b73d1427bb16ace111fc2e841",
      "85fb7b8ae25c4d489ab90f507e4134ac",
      "39dde6841f8443a3aa17cb130fe8c1a4",
      "89609af0db5a48a190be70b54d7e308f",
      "b3c93d25231240629bfdc136279d1de8",
      "784b0454140b4df095bd1e652fdb1e53",
      "a7ab628aa42445d7ba66a5c1974c2d58",
      "808b4e9d27564c0e95cb0f146f4e8068",
      "a0fc7da647a04a71b14bfc1563965f41",
      "b4c168b8749647e8a1119ebf90c2460d",
      "eee8da0d22f34854a339e98f1cfa2a55"
     ]
    },
    "executionInfo": {
     "elapsed": 6750,
     "status": "ok",
     "timestamp": 1758248209034,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "55ea9e6a",
    "outputId": "42848512-f866-465e-afec-6b458b4709e9"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "dc7e627a"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1758248209184,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "e449f9d0",
    "outputId": "91c1628a-46b1-44ba-974a-d01b473ed672"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "all_completions = train[\"completion\"].unique().tolist()\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1758248213819,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "b9b46e05",
    "outputId": "68d3d253-9097-4345-af3c-005390024a4b"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "6f7a4213"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    eval_steps=0.1,\n",
    "    save_steps=0.2,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,  # KaggleはT4なのでFP16で推論\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    completion_only_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "ZT5JfRkeLvMl"
   },
   "outputs": [],
   "source": [
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "338a5302"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "q74jCqoFjNgD"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位3件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 3\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "JFpQFTQE8qH1"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "4560c649523547e08e2c7e2e16d54793",
      "75bf18d9a6894a03b86233d6e0c94035",
      "d0903b3165c04dbf98ebee57bbbc61e8",
      "83c00b56a64b4629a77f617c68d0d1cf",
      "15215d057ffd47139b47ae1ca5609afd",
      "7cf94165cf634dcdbbe2a9fc9885bb7f",
      "a229cf3741f24d2abdebc4b68fa7e4e1",
      "3e55b47ffbc54582ac50399d3e1d9592",
      "1bbe41b2f3e944f58098fe675e70262b",
      "0f77140cd256447792478ad135882509",
      "f693d23b517f4ef8b85d459e0f15aefd",
      "adad0fae56184d68bbaec01e4fcaab04",
      "7b6e113a7a10409883c3da2c14e118aa",
      "ee5e00a1ed4f432eb6002af8c85a787b",
      "86448e6c49bc4ca68d35286a547c52ad",
      "f2a34df96d7d46ea99f2bc0eb68a3a41",
      "8c37786db8164bd3b4536249f0aae8e5",
      "859eaef2684e4f78939427fd660c376d",
      "adf9d3ba4d8049689c4cd368f8d088f3",
      "67449fd4843240d68c97cd47eb498907",
      "9a395cd24bd84f8791d7a37917b814aa",
      "6095065ac37648e38d024b213e5ce559",
      "f43c12a5a36d48a4b79e7d46e60b3d80",
      "f5bed7e7d56a4afdbd5cf0c1e966b2ca",
      "52178108c5c14f4bb84c1f53eca79a34",
      "1e16c4a1b8104833b677174deb134e1f",
      "10cc34ba9269464db3f482fce539b5c3",
      "0a24a8f6c7e740a1bca66624214a82f0",
      "866641052c9346bb9bc4dad6a7b20e51",
      "686283373ea74881896ee803756e498e",
      "e714a0e16a154c0e9d985e7dce534b1c",
      "f478524c0b8b40b283a45aab6df14b3b",
      "15fc72bef4e144dbb930a5387cd8b49d",
      "739cc9260c4d4001a25c3964c0b694d3",
      "4e98f21e3cfc41dbb584e91ccdaaa050",
      "a45ee42a081a472fa7e2e98ff7f14c17",
      "05c6c2da003d4f7b9852f4b346a598ef",
      "eb227b67e59744d29ef7b92711ea2b61",
      "0131289fbf5340c380b9238cc62eae03",
      "949ff3d194094e5fa69a5d82d2d99df8",
      "50f11c2801ff44fbbd8614bc708f011c",
      "d185550fc6fa463c87f255d0335d01c7",
      "df1eef3f4ebe4c3abd3cff747bde47e3",
      "83764254108c4fb8a20692395f598a72",
      "73c675da68a34f3896386f0df5beb4d3",
      "3ec345fc00234ff9882d23cfe6b04119",
      "e88d39c4bf3c4ea19ca2a4178a9b87a2",
      "8eac4382f9134d9092e89d836fe5134d",
      "2483f3baa48646b597310dd107ec3d3f",
      "f65331cc19d34b428ea8e5395c76c8cc",
      "4aeb59a71f5340a6a323688dd91d4ece",
      "50b323f07cc64965b835da42aa3f67de",
      "b7b3d39825994dc5ad5dfa6913797fd3",
      "449e14f29960495aa148ea3cc4cbffcd",
      "120b86ff08284ac2a3e38a5119560112",
      "86e7c482ad1141a280aa7385ab53ad0f",
      "0a7cc57e018349b79166a1020b80b175",
      "322d5227fb784d848cf41b30af2be1a9",
      "fbcfd46eda424c9ea0352a5a400aec5b",
      "4d5ecbe132ac4e3e942b463541c3279e",
      "7e373d6f2d4747feaac35bb638cc922e",
      "d63510c8cc174509b493c7ce293306be",
      "afe3003c42e24edea1e886d7d3a70f22",
      "a157a65e2c0b45b6b364edf1a0c88462",
      "819c65203bd345e78b4f3eb915b9ec4e",
      "93baa938ed5d4fa8a9fde84605fd7334"
     ]
    },
    "executionInfo": {
     "elapsed": 39307,
     "status": "ok",
     "timestamp": 1758248253146,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1e7dcc50",
    "outputId": "2ee776ce-2906-4791-f5f2-d50941f1f1eb"
   },
   "outputs": [],
   "source": [
    "# Trainerの設定\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=lora_config,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "CO-xcuAPJDob",
    "outputId": "3a75d424-e701-4a20-959d-d691abe705f4"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "6ff91cd0"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(CFG.output_dir_path)\n",
    "tokenizer.save_pretrained(CFG.output_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "id": "AiSt1UAdxB-B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
