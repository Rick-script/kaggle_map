{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5437,
     "status": "ok",
     "timestamp": 1758243946063,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "998f0e04",
    "outputId": "f7a26e13-ebe2-4520-9dff-08d24b979b7f"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp001_qwen3-8b-full\n",
    "\n",
    "    !pip install -q trl==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "8d16216d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "9c3d4b52"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp001_qwen3-8b-full\"\n",
    "    model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    output_dir_path = \"output/\"\n",
    "    log_dir_path = \"logs/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 2\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 2e-5\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 32\n",
    "    lora_alpha = 64\n",
    "    lora_dropout = 0.05\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\"]\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"You are a specialist in identifying the types of misunderstandings that arise from students' answers to math problems.\n",
    "Based on the information provided below, please determine what kind of misunderstanding the student has.\n",
    "\n",
    "Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "513676b3"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "bc7a98ad"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "5b46ca05"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "a9d252ef"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "c7626f3a"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"Category\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"Category\"].str.replace(\"False\", \"True\"),\n",
    "        df[\"Category\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"Category\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"Category\"].str.replace(\"True\", \"False\"),\n",
    "        df[\"Category\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "b3777e95"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1758243957927,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "23c3d5ca",
    "outputId": "2975a71c-d227-4e38-e005-8273364e7607"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "f1b0f41e"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "9d534d23"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8bf02a4673a646d8bbc5394d23200931",
      "140b7f1bf6f64d87ab910139afc4135e",
      "803c5ee3f663450091cd47d1913224a9",
      "63565901258c474985fd27ade26437a6",
      "0d3e0fac24634dd4bc4a2c6936fbe629",
      "31b8f9c32ac3495d99f4d6bf5d7a97c1",
      "312514e0d8fc43e185f5aa160aecac16",
      "c50eb5b47f514f33bcbbc130178383e0",
      "daba843a0f174ebc9cb80f6e5a7f6479",
      "0c92f5884e074d9fa1722b3946db713a",
      "b7e8ee5e1f1d40af89c9aa936e9b69d9"
     ]
    },
    "executionInfo": {
     "elapsed": 7338,
     "status": "ok",
     "timestamp": 1758243965325,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "55ea9e6a",
    "outputId": "c10eea0b-2660-418f-ba04-acf8d96e8482"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "dc7e627a"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1758243965530,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "e449f9d0",
    "outputId": "d063cb6b-bf1c-4a52-9050-f1e111231431"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "all_completions = train[\"completion\"].unique().tolist()\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "executionInfo": {
     "elapsed": 4285,
     "status": "ok",
     "timestamp": 1758243969817,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "b9b46e05",
    "outputId": "8b3924b6-285a-4106-bba3-6f449b895aa7"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "6f7a4213"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    eval_steps=0.1,\n",
    "    save_steps=0.2,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,  # KaggleはT4なのでFP16で推論\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    completion_only_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "ZT5JfRkeLvMl"
   },
   "outputs": [],
   "source": [
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "338a5302"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "q74jCqoFjNgD"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位3件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 3\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "JFpQFTQE8qH1"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233,
     "referenced_widgets": [
      "b34bb9c4325e48a69608cfe297c84f4b",
      "402ca406120d45a7b4411607382e8610",
      "2065c0789d794f87ac1dcd6f119892e5",
      "84a824e70a57456bb28a5c5ca489434b",
      "44a83fc3265d464d807769063c94e93d",
      "7d49bf85213a479b9241ae837240de88",
      "003678c78c164639aef2d2c070859c2c",
      "a944576e0db445e1b94cb89fa31e5bbf",
      "450e60b79c6a402888bda713fc828a23",
      "1781bc2b42d04d5c961a495a41bbab82",
      "bc91421cd2294fdf8a84f55f47b65ec4",
      "d417c30c42f24e9dad72f59e11574344",
      "bacb12a1af6347b7a2d5a32480f56c93",
      "73ea0ebe02834659a6c17edfa970b592",
      "fa79b1f7ce3449e4be22bc29753dc4f6",
      "afdf40f5eed547bd8d4df9fdecd7c951",
      "303c1d1250b34a21a18cd40ae2135101",
      "152f7402025e42929f4bc25b0af918c2",
      "a3cd3b8fe880417e953f7589a4e38c53",
      "3dbb9016cd2e41bdb93132511dbe94f6",
      "b7b35ffad7914d95ae992770617f1f3d",
      "d62ee47ca76945cda672f7fd8ae1b824",
      "ab487b79c2c045089bbe3123d802ff55",
      "8bbf9d423a104ef6952c13d7a5b52f56",
      "4376e09a1bfd4a139bc34d6a072cf809",
      "00d29db55e7f4f50b1c9657b63b58af3",
      "c9d97d42e9414894a3593086ee96709a",
      "ba6bc1432f4f43c38d32c2d647f7fbf2",
      "52a673425bbb4ceca3fa923b54de5d81",
      "a4aa9882765444ae87a6fb37e5f70f33",
      "e218580a7d4f4bfd81ed862c15313ed1",
      "d645cc9c20cf484980309664e4e884b0",
      "8419806fa745486da7f8625b049a9b6d",
      "0aeef8321554430a9cfff76e1616904b",
      "f8ad991e4df54c04a08d296599f2592f",
      "73bb898ca32549f2adeed1be5c80f6a7",
      "ad20f9da467243b7830672dc75ab97e9",
      "498b60058ff74117b2c8c870a9802ccf",
      "26fa03428bad45e1be252719e6131c63",
      "86082575e70d4e9e9e0fa8808e8800c9",
      "a66c641575614bc5a992497a8a45e756",
      "633e79837cde4032b969946924c4a966",
      "570dbf9b37794a64b74be4dde8d859db",
      "e04be9f274964c528fbc6f50b6eb4b82",
      "49391268478044ff97893e2160bf63e4",
      "a04a5daa72534c5b9e12a7f0e5227c77",
      "8d3b08c0e229431ea4615a3059b0ea82",
      "7676cb75b4c745e697f1736e010c8730",
      "6872ef2a77f4401299bd122c5c943628",
      "2c8d482e92e844309730294b07b3d172",
      "943fedbaa66641299268122c362f350a",
      "76bd1809cdca4a48bbf0aead81599898",
      "97275df6bf394f789478d549a1535246",
      "b7457f62d6a3450c9348000cb913e41b",
      "0499b0f803b94f3fbbf45ab7edd435ff",
      "6855d091b02d46b2b585d2dd2473f18f",
      "0bb0e96101b0437b868bad8216f36149",
      "c16739a6c1d74701be267fbfa6205982",
      "2ed1888875f943c5835a635375f1665e",
      "ee2ddfdeea7c47248042092fe0dd9917",
      "a12a5a616d3a4205a1ee54de7ac66bb9",
      "7f14b532dca840029f8937ec158b81ba",
      "e3e79789d5b143bfb8d5c3d415cbe4c2",
      "ad843f4df26b47969d8348481101a0a1",
      "05c8ed17545943a79b6a015719d010d7",
      "679793c486b7421faad4003cbdb7eedc"
     ]
    },
    "executionInfo": {
     "elapsed": 35815,
     "status": "ok",
     "timestamp": 1758244005677,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1e7dcc50",
    "outputId": "a778d738-7d37-4e70-b711-3a962863519e"
   },
   "outputs": [],
   "source": [
    "# Trainerの設定\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    # peft_config=lora_config,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")\n",
    "# trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 6233909,
     "status": "ok",
     "timestamp": 1758252277885,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "k27tr3v2JKPq",
    "outputId": "055e2809-cc07-408d-f47c-8c551418057b"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "vuB6iOYQI3vU"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(\"/content/model\")\n",
    "tokenizer.save_pretrained(\"/content/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 765,
     "status": "ok",
     "timestamp": 1758254468817,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vMxhXbS9IRCa",
    "outputId": "8be5335d-a8da-4552-d6a3-fc79b5649992"
   },
   "outputs": [],
   "source": [
    "# Hugging Faceにアップロード\n",
    "from huggingface_hub import HfApi\n",
    "from huggingface_hub import upload_folder\n",
    "\n",
    "api = HfApi()\n",
    "api.create_repo(CFG.exp_name, private=True)\n",
    "\n",
    "upload_folder(\n",
    "    repo_id=\"ricky0526/\"+CFG.exp_name,\n",
    "    folder_path=\"/content/model\",\n",
    "    commit_message=\"Initial upload\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "id": "PsCZlEwrIwJO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
