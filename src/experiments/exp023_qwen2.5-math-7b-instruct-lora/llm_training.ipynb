{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10570,
     "status": "ok",
     "timestamp": 1759335375989,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "998f0e04",
    "outputId": "86297c87-0388-43eb-8419-d4a4073d0351"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp023_qwen2.5-math-7b-instruct-lora\n",
    "\n",
    "    !pip install -q -U trl==0.23.0\n",
    "    !pip install -q accelerate==1.10.1 bitsandbytes==0.47.0 mpi4py==4.1.0 deepspeed==0.17.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "8d16216d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "id": "ISfviCnlA7EY"
   },
   "outputs": [],
   "source": [
    "# DeepSpeed requires a distributed environment even when only one process is used.\n",
    "# This emulates a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9995\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "9c3d4b52"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp023_qwen2.5-math-7b-instruct-lora\"\n",
    "    model_name = \"Qwen/Qwen2.5-Math-7B-Instruct\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    output_dir_path = \"output/\"\n",
    "    log_dir_path = \"logs/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 8\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 8e-5\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 64\n",
    "    lora_alpha = 128\n",
    "    lora_dropout = 0.01\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\"]\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"You are a specialist in identifying the types of misunderstandings that arise from students' answers to math problems.\n",
    "Based on the information provided below, please determine what kind of misunderstanding the student has.\n",
    "\n",
    "Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "id": "513676b3"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "bc7a98ad"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "5b46ca05"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "a9d252ef"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "c7626f3a"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 6 \\)\", r\"\\( 9 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 9 \\)\", r\"\\( 6 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "b3777e95"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759335388784,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "23c3d5ca",
    "outputId": "d382c70c-e139-4628-ef7b-efff37405898"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "f1b0f41e"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].reset_index(drop=True).sample(frac=1, random_state=CFG.seed).reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "9d534d23"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "3cekyBh4BdsD"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "6c7e5187d7034caba032f4069fb9b78f"
     ]
    },
    "executionInfo": {
     "elapsed": 8623,
     "status": "ok",
     "timestamp": 1759335397591,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "55ea9e6a",
    "outputId": "3c45c2b5-d964-45d4-ebec-1866ec3612f5"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    # quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "dc7e627a"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1759335397806,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "e449f9d0",
    "outputId": "5cd683f5-9215-43d7-bd1e-0f734ab56fd6"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "all_completions = train[\"completion\"].unique().tolist()\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4421,
     "status": "ok",
     "timestamp": 1759335402226,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "b9b46e05",
    "outputId": "1560410b-5bd3-409a-bdf7-66d864b65745"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "id": "c2N6m7-YBv13"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero1.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": \"auto\"\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "            \"pin_memory\": true\n",
    "        }\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "6f7a4213"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=0.195,\n",
    "    # save_steps=0.2,\n",
    "    # save_total_limit=1,\n",
    "    # metric_for_best_model=\"map@3\",\n",
    "    # greater_is_better=True,\n",
    "    # load_best_model_at_end=True,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,  # KaggleはT4なのでFP16で推論\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=False,\n",
    "    completion_only_loss=True,\n",
    "    deepspeed=\"ds_config_zero1.json\",\n",
    "    dataset_num_proc=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "ZT5JfRkeLvMl"
   },
   "outputs": [],
   "source": [
    "# 追加済みの全ラベルをIDに\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(all_completions)\n",
    "\n",
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    "    modules_to_save=[\"lm_head\"],\n",
    "    trainable_token_indices={\"embed_tokens\": new_token_ids}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "338a5302"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "q74jCqoFjNgD"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位3件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 3\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "id": "JFpQFTQE8qH1"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "45edb2421cb24d42ae507a4f015645ae",
      "0ff3f70eb6374b85b5969f0b35649910",
      "40f9f48cf6db4e52982169d8e00d2131",
      "8f9c1286260042a78c3f0d49ced49d4a",
      "7ff95513e6dd44b481b4d305ff907cb3",
      "f64444880f3949589cd9f1e96064a83b"
     ]
    },
    "executionInfo": {
     "elapsed": 21852,
     "status": "ok",
     "timestamp": 1759335425928,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1e7dcc50",
    "outputId": "b880daa0-230b-4ebc-982f-1478c0241f95"
   },
   "outputs": [],
   "source": [
    "# Trainerの設定\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=lora_config,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759335425939,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "pXfPvcwFCajv",
    "outputId": "9fdc932b-db94-48e9-aaf3-8a2c8e85c71d"
   },
   "outputs": [],
   "source": [
    "for n, p in trainer.model.named_parameters():\n",
    "    if \"embed_tokens\" in n or \"lm_head\" in n:\n",
    "        print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 3300686,
     "status": "ok",
     "timestamp": 1759338754836,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "k27tr3v2JKPq",
    "outputId": "150c3220-73ba-4406-9577-8393506ff4d3"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "executionInfo": {
     "elapsed": 31415,
     "status": "ok",
     "timestamp": 1759341605716,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "6ff91cd0"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(CFG.output_dir_path + \"/model\")\n",
    "tokenizer.save_pretrained(CFG.output_dir_path + \"/model\")\n",
    "\n",
    "# モデルの設定を更新\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "kuamzg65rlf"
   },
   "source": [
    "## Validation データの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1759341779525,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gckmctdvdt"
   },
   "outputs": [],
   "source": [
    "def predict_category_probabilities(model, tokenizer, prompts, category_token_ids, batch_size=8):\n",
    "    \"\"\"\n",
    "    validationデータの各プロンプトに対してカテゴリの確率を予測する\n",
    "\n",
    "    Args:\n",
    "        model: 学習済みモデル\n",
    "        tokenizer: トークナイザー\n",
    "        prompts: 入力プロンプトのリスト\n",
    "        category_token_ids: カテゴリトークンのIDリスト\n",
    "        batch_size: バッチサイズ\n",
    "\n",
    "    Returns:\n",
    "        各レコードのカテゴリ確率のリスト\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Predicting probabilities\"):\n",
    "        batch_prompts = prompts[i:i+batch_size]\n",
    "\n",
    "        # トークナイズ\n",
    "        inputs = tokenizer(\n",
    "            batch_prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=CFG.max_len\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # モデル推論\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            max_indices = torch.argmax(logits, dim=-1)\n",
    "            print(logits.shape)\n",
    "            print(tokenizer.batch_decode(max_indices[:,-4]))\n",
    "\n",
    "            # 最後のトークンのlogitsを取得\n",
    "            last_logits = logits[:, -1, :]\n",
    "\n",
    "            # カテゴリトークンのlogitsのみ抽出\n",
    "            category_logits = last_logits[:, category_token_ids]\n",
    "\n",
    "            # softmaxで確率に変換\n",
    "            category_probs = torch.softmax(category_logits, dim=-1)\n",
    "\n",
    "            # CPUに移動してnumpyに変換\n",
    "            category_probs = category_probs.cpu().to(torch.float64).numpy()\n",
    "            all_probs.extend(category_probs)\n",
    "\n",
    "    return np.array(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1759341780299,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "2bqtuc57l7s",
    "outputId": "fe348830-e46d-4c2c-a4bf-08ec1bd4937a"
   },
   "outputs": [],
   "source": [
    "# カテゴリトークンIDの取得\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(all_completions)\n",
    "print(f\"Category token IDs: {len(new_token_ids)}\")\n",
    "\n",
    "# validationデータの準備\n",
    "val_prompts = val_df[\"prompt\"].head().tolist()\n",
    "print(f\"Validation prompts: {len(val_prompts)}\")\n",
    "\n",
    "# 確率予測の実行\n",
    "print(\"Starting probability prediction...\")\n",
    "probabilities = predict_category_probabilities(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompts=val_prompts,\n",
    "    category_token_ids=new_token_ids,\n",
    "    batch_size=CFG.per_device_eval_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759340814181,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "0Xfbj58q4ksy",
    "outputId": "1a879a29-acc6-43fe-d736-2263487d6cf5"
   },
   "outputs": [],
   "source": [
    "all_completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759340802858,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "KxXeO1Ex4ixu",
    "outputId": "2a0986a6-1063-46fe-ac2c-850f767d308e"
   },
   "outputs": [],
   "source": [
    "new_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "id": "c5nch8015a8"
   },
   "outputs": [],
   "source": [
    "# 結果をDataFrameに変換\n",
    "prob_df = pd.DataFrame(probabilities, columns=all_completions)\n",
    "\n",
    "# validationデータの情報を追加\n",
    "result_df = val_df[[\"row_id\", \"QuestionId\", \"MC_Answer\", \"Category\", \"Misconception\", \"completion\"]].copy().reset_index(drop=True)\n",
    "result_df = pd.concat([result_df, prob_df], axis=1)\n",
    "\n",
    "# 結果を保存\n",
    "output_path = f\"{CFG.output_dir_path}/validation_probabilities.csv\"\n",
    "result_df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759340544253,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "ZGSO1uL13arU",
    "outputId": "d4da7104-60f0-4915-bfcc-43f97cc2639f"
   },
   "outputs": [],
   "source": [
    "result_df[result_df[\"True_Correct:NA\"]>=0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4882,
     "status": "ok",
     "timestamp": 1759340590214,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "tjiigt15dbn",
    "outputId": "37e07494-276a-41a9-d2e1-71017cd713d8"
   },
   "outputs": [],
   "source": [
    "# カテゴリごとのメトリクス計算\n",
    "def calculate_category_metrics(result_df, prob_df):\n",
    "    \"\"\"カテゴリごとのMAP@3, Top1_Accuracy, Top3_Accuracyを計算\"\"\"\n",
    "    metrics_list = []\n",
    "\n",
    "    for category in result_df[\"Category\"].unique():\n",
    "        category_mask = result_df[\"Category\"] == category\n",
    "        category_data = result_df[category_mask]\n",
    "        category_probs = prob_df[category_mask]\n",
    "\n",
    "        if len(category_data) == 0:\n",
    "            continue\n",
    "\n",
    "        # 各レコードの予測top3を取得\n",
    "        top3_predictions = []\n",
    "        top1_correct = 0\n",
    "        top3_correct = 0\n",
    "        map3_scores = []\n",
    "\n",
    "        for idx, (_, row) in enumerate(category_data.iterrows()):\n",
    "            actual_completion = row[\"completion\"]\n",
    "            probs = category_probs.iloc[idx]\n",
    "\n",
    "            # top3予測を取得\n",
    "            top3_cats = probs.nlargest(3).index.tolist()\n",
    "            top3_predictions.append(top3_cats)\n",
    "\n",
    "            # Top1 Accuracy\n",
    "            if top3_cats[0] == actual_completion:\n",
    "                top1_correct += 1\n",
    "\n",
    "            # Top3 Accuracy\n",
    "            if actual_completion in top3_cats:\n",
    "                top3_correct += 1\n",
    "\n",
    "            # MAP@3計算\n",
    "            map3_score = 0\n",
    "            for rank, pred_cat in enumerate(top3_cats):\n",
    "                if pred_cat == actual_completion:\n",
    "                    map3_score = 1.0 / (rank + 1)\n",
    "                    break\n",
    "            map3_scores.append(map3_score)\n",
    "\n",
    "        # メトリクス計算\n",
    "        sample_count = len(category_data)\n",
    "        map3 = np.mean(map3_scores)\n",
    "        top1_acc = top1_correct / sample_count\n",
    "        top3_acc = top3_correct / sample_count\n",
    "\n",
    "        metrics_list.append({\n",
    "            \"Category\": category,\n",
    "            \"Sample_Count\": sample_count,\n",
    "            \"MAP@3\": map3,\n",
    "            \"Top1_Accuracy\": top1_acc,\n",
    "            \"Top3_Accuracy\": top3_acc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(metrics_list)\n",
    "\n",
    "# カテゴリごとのメトリクス計算\n",
    "category_metrics = calculate_category_metrics(result_df, prob_df)\n",
    "category_metrics = category_metrics.sort_values(\"Sample_Count\", ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Category-wise Performance Metrics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Category':<30} {'Count':<8} {'MAP@3':<8} {'Top1_Acc':<10} {'Top3_Acc':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for _, row in category_metrics.iterrows():\n",
    "    print(f\"{row['Category']:<30} {row['Sample_Count']:<8} {row['MAP@3']:<8.4f} {row['Top1_Accuracy']:<10.4f} {row['Top3_Accuracy']:<10.4f}\")\n",
    "\n",
    "# マイクロ平均（サンプル数で加重）\n",
    "weights     = category_metrics['Sample_Count']\n",
    "micro_map3  = np.average(category_metrics['MAP@3'], weights=weights)\n",
    "micro_top1  = np.average(category_metrics['Top1_Accuracy'], weights=weights)\n",
    "micro_top3  = np.average(category_metrics['Top3_Accuracy'], weights=weights)\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Micro Avg (by sample)':<30} {len(result_df):<8} {micro_map3:<8.4f} {micro_top1:<10.4f} {micro_top3:<10.4f}\")\n",
    "\n",
    "# カテゴリメトリクスをCSVで保存\n",
    "category_metrics_path = f\"{CFG.output_dir_path}/category_metrics.csv\"\n",
    "category_metrics.to_csv(category_metrics_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "AqW5vZKmYpb3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
