{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10373,
     "status": "ok",
     "timestamp": 1759694072158,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "NhOathqKR7sn",
    "outputId": "4490250d-7684-4af4-ad34-d7d68c283a55"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp025_qwen2.5-14b-lora-softlabel\n",
    "\n",
    "    !pip install -q -U trl==0.23.0\n",
    "    !pip install -q accelerate==1.10.1 bitsandbytes==0.47.0 mpi4py==4.1.0 deepspeed==0.17.6 transformers==4.56.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11258,
     "status": "ok",
     "timestamp": 1759694083419,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "JLsCVK1JR7so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from trl.trainer.sft_trainer import DataCollatorForLanguageModeling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759694083421,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "sA_IA3vtR7so"
   },
   "outputs": [],
   "source": [
    "# DeepSpeed requires a distributed environment even when only one process is used.\n",
    "# This emulates a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9995\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759694083430,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "EShEkQPER7sp"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp025_qwen2.5-14b-lora-softlabel\"\n",
    "    model_name = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    soft_label_path = f\"{comp_dir_path}/qwen2.5-14b/validation_logprobs_merged.pkl\"\n",
    "    output_dir_path = \"output/\"\n",
    "    log_dir_path = \"logs/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 8\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 8e-5\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 64\n",
    "    lora_alpha = 128\n",
    "    lora_dropout = 0.01\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\", \"soft_labels\"]\n",
    "\n",
    "    # ============== ソフトラベル設定 =============\n",
    "    temperature = 1.0\n",
    "    alpha = 0.5\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"You are a specialist in identifying the types of misunderstandings that arise from students' answers to math problems.\n",
    "Based on the information provided below, please determine what kind of misunderstanding the student has.\n",
    "\n",
    "Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759694083436,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "lj_ScryyR7sp"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759694083444,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "4emKGBEBR7sp"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9WiUp2lR7sp"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759694083452,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "TokrfpxTR7sq"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759694083461,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "cKQJwcOhR7sq"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 6 \\)\", r\"\\( 9 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 9 \\)\", r\"\\( 6 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759694083470,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "3nk769TSR7sq"
   },
   "outputs": [],
   "source": [
    "def load_soft_labels(soft_label_path: str, all_completions: list) -> dict:\n",
    "    \"\"\"ソフトラベルを読み込み、64カテゴリの確率分布に拡張する\"\"\"\n",
    "    with open(soft_label_path, \"rb\") as f:\n",
    "        soft_labels_raw = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded soft labels for {len(soft_labels_raw)} samples\")\n",
    "\n",
    "    # 64カテゴリの確率分布に拡張\n",
    "    expanded_soft_labels = {}\n",
    "    for idx, soft_label_dict in soft_labels_raw.items():\n",
    "        # 64カテゴリの確率ベクトルを初期化（全て0.0）\n",
    "        full_probs = np.zeros(len(all_completions), dtype=np.float32)\n",
    "\n",
    "        # ソフトラベルに存在するカテゴリの確率を設定\n",
    "        for category, prob in soft_label_dict.items():\n",
    "            if category in all_completions:\n",
    "                cat_idx = all_completions.index(category)\n",
    "                full_probs[cat_idx] = prob\n",
    "\n",
    "        # 確率の合計が1になるように正規化（ソフトラベルの確率の合計が1未満の場合）\n",
    "        prob_sum = np.sum(full_probs)\n",
    "        if prob_sum > 0:\n",
    "            full_probs = full_probs / prob_sum\n",
    "\n",
    "        expanded_soft_labels[idx] = full_probs\n",
    "\n",
    "    return expanded_soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1759694084361,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "P3z0lZ8xR7sq",
    "outputId": "52522e23-fd98-4425-9762-de135e9aa560"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)\n",
    "\n",
    "# 全てのラベルを取得（64カテゴリ）\n",
    "all_completions = sorted(train[\"completion\"].unique().tolist())\n",
    "print(f\"Total categories: {len(all_completions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1759694085843,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "KvOc_xOdR7sr",
    "outputId": "d2d182db-5d16-4e25-d10c-cb22734c8194"
   },
   "outputs": [],
   "source": [
    "# ソフトラベルの読み込み\n",
    "soft_labels = load_soft_labels(CFG.soft_label_path, all_completions)\n",
    "\n",
    "# trainデータにソフトラベルを追加\n",
    "train[\"soft_labels\"] = train.index.map(lambda idx: soft_labels.get(idx, np.zeros(len(all_completions), dtype=np.float32)))\n",
    "\n",
    "print(f\"Added soft labels for {len(train)} samples\")\n",
    "print(f\"Example soft label shape: {train['soft_labels'].iloc[0].shape}\")\n",
    "print(f\"Example soft label sum: {np.sum(train['soft_labels'].iloc[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759694085852,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "8M99HHsKR7sr",
    "outputId": "6e076117-fbe1-497f-9bb4-9d100a1a3b2a"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])\n",
    "print(train[\"completion\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1759694086119,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vjZUydQsR7sr"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].sample(frac=1, random_state=CFG.seed).reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xm0kpFPR7sr"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759694086129,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "oWCGcu9IR7sr"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0ef3a2cd743b4cbba5b88fb8436686e2",
      "e04ff2828db04c65a9c07872d663e5fb",
      "ee406d56008a459c91583d04786698eb",
      "cc487db6d4e242f5885980565d36313d",
      "3a4d539972a84e1086b2ddf3c9bd4585",
      "4fdb1f4101ec4a2497ef6428bb90c46e",
      "de80532b42c7418d961cc2200421b00d",
      "dbb29408a3734524978ab0be52d421a5",
      "cea0bb95c789411f96977f6dcdd0daae",
      "fc8e86770da045cab2d6a8414aabf856",
      "2c4ddc6cb1e6494cb98be3e662990052"
     ]
    },
    "executionInfo": {
     "elapsed": 38289,
     "status": "ok",
     "timestamp": 1759694124419,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vnxnv8WdR7sr",
    "outputId": "8e7f22ec-3db3-4b69-9ea3-39172d64c4b2"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759694124423,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Vb3n77IwR7sr"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1759694124545,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "XQr9BrseR7sr",
    "outputId": "8868fb1a-b53f-4e54-d7b4-e80ca7557c34"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 4335,
     "status": "ok",
     "timestamp": 1759694128881,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Xkr1qpKLR7sr",
    "outputId": "11afa1ab-0996-41f3-b7a8-7617d7f1b120"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759694128896,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gH24xZA-R7sr"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero1.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": \"auto\"\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "            \"pin_memory\": true\n",
    "        }\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2305,
     "status": "ok",
     "timestamp": 1759694131204,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "J5OJ5ormR7sr"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=0.195,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=False,\n",
    "    completion_only_loss=True,\n",
    "    deepspeed=\"ds_config_zero1.json\",\n",
    "    dataset_num_proc=8,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1759694131206,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "nndt9wRoR7sr"
   },
   "outputs": [],
   "source": [
    "# 追加済みの全ラベルをIDに\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(all_completions)\n",
    "\n",
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    "    modules_to_save=[\"lm_head\"],\n",
    "    trainable_token_indices={\"embed_tokens\": new_token_ids}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxALZ_PTR7sr"
   },
   "source": [
    "### カスタムトレーナー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759694131214,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "QrBGkcslLvDj"
   },
   "outputs": [],
   "source": [
    "class SoftLabelCollator:\n",
    "    \"soft_labelsをcustom_trainerに渡す\"\n",
    "    def __init__(self, base_collator):\n",
    "        self.base_collator = base_collator\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        has_soft_labels = \"soft_labels\" in examples[0]\n",
    "        if has_soft_labels:\n",
    "            soft_labels = [ex[\"soft_labels\"] for ex in examples]\n",
    "        else:\n",
    "            soft_labels = None\n",
    "\n",
    "        # 既存のcollatorを通す\n",
    "        batch = self.base_collator(examples)\n",
    "\n",
    "        # soft_labels をそのまま追加\n",
    "        if has_soft_labels:\n",
    "            batch[\"soft_labels\"] = soft_labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759694131230,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gqOAqy-fz0KF"
   },
   "outputs": [],
   "source": [
    "class SoftLabelSFTTrainer(SFTTrainer):\n",
    "    \"\"\"ソフトラベル学習に対応したカスタムSFTTrainer\"\"\"\n",
    "\n",
    "    def __init__(self, temperature=1.0, alpha=0.7, category_token_ids=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.category_token_ids = (torch.tensor(category_token_ids) if category_token_ids else None)\n",
    "        self.kl_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"ソフトラベルとハードラベルの混合損失を計算\"\"\"\n",
    "\n",
    "        # ソフトラベル取得\n",
    "        soft_labels = inputs.pop(\"soft_labels\", None)\n",
    "\n",
    "        # 通常のforward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # ソフトラベルとカテゴリトークンが指定されている場合のみ特殊処理\n",
    "        # ------------------------------------------------------------\n",
    "        if soft_labels is not None and self.category_token_ids is not None:\n",
    "            labels = inputs.get(\"labels\", None)\n",
    "            if labels is None:\n",
    "                return outputs.loss if not return_outputs else (outputs.loss, outputs)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            category_positions = []\n",
    "            actual_category_labels = []\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # カテゴリトークンの位置を特定し、予測すべき位置を抽出\n",
    "            # ------------------------------------------------------------\n",
    "            for b in range(batch_size):\n",
    "                sample_labels = labels[b]\n",
    "                cat_mask = torch.zeros_like(sample_labels, dtype=torch.bool)\n",
    "\n",
    "                for cat_id in self.category_token_ids:\n",
    "                    cat_mask |= (sample_labels == cat_id.to(sample_labels.device))\n",
    "\n",
    "                cat_positions = torch.nonzero(cat_mask, as_tuple=True)[0]\n",
    "\n",
    "                if len(cat_positions) > 0:\n",
    "                    # 最初のカテゴリトークンの1つ前を予測位置とする\n",
    "                    pos = max(cat_positions[0].item() - 1, 0)\n",
    "                    actual_category_labels.append(sample_labels[cat_positions[0]].item())\n",
    "                else:\n",
    "                    # カテゴリトークンが見つからない場合、最後の有効トークンを使う\n",
    "                    print(\"カテゴリトークンが見つかりません\")\n",
    "                    valid_mask = sample_labels != -100\n",
    "                    valid_positions = torch.nonzero(valid_mask, as_tuple=True)[0]\n",
    "                    if len(valid_positions) > 0:\n",
    "                        pos = valid_positions[-2].item() if len(valid_positions) > 1 else 0\n",
    "                        actual_category_labels.append(sample_labels[valid_positions[-1]].item())\n",
    "                    else:\n",
    "                        pos = logits.size(1) - 1\n",
    "                        actual_category_labels.append(-100)\n",
    "\n",
    "                category_positions.append(pos)\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 各サンプルの対象位置のlogitsを取得\n",
    "            # ------------------------------------------------------------\n",
    "            selected_logits = torch.stack([\n",
    "                logits[i, pos, :] for i, pos in enumerate(category_positions)\n",
    "            ])\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # デバッグ出力\n",
    "            # ------------------------------------------------------------\n",
    "            # if self.state.global_step % 50 == 0:\n",
    "            #     with torch.no_grad():\n",
    "            #         print(f\"\\n{'='*80}\")\n",
    "            #         print(f\"[Step {self.state.global_step}] Token predictions at completion position:\")\n",
    "\n",
    "            #         for i in range(min(3, batch_size)):\n",
    "            #             print(f\"\\n  Sample {i} (position={category_positions[i]}):\")\n",
    "\n",
    "            #             # --- (1) 全語彙からのトップ5 ---\n",
    "            #             all_probs = F.softmax(selected_logits[i], dim=-1)\n",
    "            #             top5_probs, top5_indices = torch.topk(all_probs, k=5, dim=-1)\n",
    "\n",
    "            #             print(\"    Top-5 from ALL vocabulary:\")\n",
    "            #             for idx, prob in zip(top5_indices, top5_probs):\n",
    "            #                 token_id = idx.item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"token_{token_id}\"\n",
    "            #                 )\n",
    "            #                 marker = \" [CAT]\" if token_id in self.category_token_ids else \"\"\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}{marker}\")\n",
    "\n",
    "            #             # --- (2) カテゴリトークンのみのトップ5 ---\n",
    "            #             cat_logits = selected_logits[i][self.category_token_ids.to(selected_logits.device)]\n",
    "            #             cat_probs = F.softmax(cat_logits, dim=-1)\n",
    "            #             top5_cat_probs, top5_cat_indices = torch.topk(\n",
    "            #                 cat_probs, k=min(5, cat_probs.size(-1)), dim=-1\n",
    "            #             )\n",
    "\n",
    "            #             print(\"    Top-5 CATEGORY tokens (Model Prediction):\")\n",
    "            #             for idx, prob in zip(top5_cat_indices, top5_cat_probs):\n",
    "            #                 token_id = self.category_token_ids[idx].item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"cat_{token_id}\"\n",
    "            #                 )\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "            #             # --- (3) ソフトラベルのトップ5 ---\n",
    "            #             soft_label_tensor = torch.as_tensor(\n",
    "            #                 soft_labels[i], dtype=torch.float32\n",
    "            #             )\n",
    "            #             top5_soft_probs, top5_soft_indices = torch.topk(\n",
    "            #                 soft_label_tensor, k=min(5, len(soft_label_tensor))\n",
    "            #             )\n",
    "\n",
    "            #             print(\"    Top-5 SOFT LABELS (Target Distribution):\")\n",
    "            #             for idx, prob in zip(top5_soft_indices, top5_soft_probs):\n",
    "            #                 token_id = self.category_token_ids[idx].item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"soft_{token_id}\"\n",
    "            #                 )\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "            #             # --- (4) 正解ラベルを表示 ---\n",
    "            #             if i < len(actual_category_labels) and actual_category_labels[i] != -100:\n",
    "            #                 true_label_id = actual_category_labels[i]\n",
    "            #                 true_label_str = (\n",
    "            #                     self.processing_class.decode([true_label_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"label_{true_label_id}\"\n",
    "            #                 )\n",
    "\n",
    "            #                 if true_label_id in self.category_token_ids:\n",
    "            #                     cat_index = (self.category_token_ids == true_label_id).nonzero(as_tuple=True)[0]\n",
    "            #                     if len(cat_index) > 0:\n",
    "            #                         true_prob = cat_probs[cat_index[0]].item()\n",
    "            #                         print(f\"    TRUE LABEL: {true_label_str} (prob={true_prob:.4f})\")\n",
    "            #                     else:\n",
    "            #                         print(f\"    TRUE LABEL: {true_label_str}\")\n",
    "            #                 else:\n",
    "            #                     print(f\"    TRUE LABEL: {true_label_str} [NOT A CATEGORY TOKEN]\")\n",
    "            #             else:\n",
    "            #                 print(\"    TRUE LABEL: Not found\")\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # ソフトラベル損失（KL Divergence）の計算\n",
    "            # ------------------------------------------------------------\n",
    "            category_logits = selected_logits[:, self.category_token_ids.to(selected_logits.device)]\n",
    "            category_logits = category_logits / self.temperature\n",
    "            log_probs = F.log_softmax(category_logits, dim=-1)\n",
    "\n",
    "            soft_labels_tensor = torch.stack([\n",
    "                torch.as_tensor(sl, dtype=torch.float32) for sl in soft_labels\n",
    "            ]).to(log_probs.device)\n",
    "\n",
    "            # nn.KLDivLossを使用\n",
    "            kl_loss = self.kl_criterion(log_probs, soft_labels_tensor)\n",
    "            kl_loss *= self.temperature ** 2\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 損失の混合\n",
    "            # ------------------------------------------------------------\n",
    "            hard_loss = outputs.loss if outputs.loss is not None else 0\n",
    "            total_loss = (1 - self.alpha) * hard_loss + self.alpha * kl_loss\n",
    "\n",
    "            # if self.state.global_step % 50 == 0:\n",
    "            #     print(f\"\\n  Losses - Hard: {hard_loss.item():.4f}, KL: {kl_loss.item():.4f}, Total: {total_loss.item():.4f}\")\n",
    "            #     print('=' * 80)\n",
    "\n",
    "        else:\n",
    "            # ソフトラベルを使用しない通常損失\n",
    "            total_loss = outputs.loss\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhVu51fNULHR"
   },
   "source": [
    "### 評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759694131238,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "LAxhktY2UKHP"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位5件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 5\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1759694131283,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1ArxPkjxUKJz"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO2rpJN6Us3V"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759694131284,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "SX2rWXZ_Q6TZ"
   },
   "outputs": [],
   "source": [
    "# collatorの定義\n",
    "base = DataCollatorForLanguageModeling(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    completion_only_loss=True,\n",
    "    padding_free=False\n",
    ")\n",
    "collator = SoftLabelCollator(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "ff484924cc2b437696d3926d73890cc0",
      "801702833a3a49588c7b652ad4ecc1f6",
      "a9dbcec29baa4df5aaf56f5a15178865",
      "783d0c5359004809a8a0a94213b43f7d",
      "c9b0b0925b2e4ee19d9b980079e8479a",
      "89d16de9ee0344e7ae187bd4b1c4336a",
      "bd9339910d6c4ed29e8617e8dadcf317",
      "ee939637ee3345de8fec179a5e6ac066",
      "96487e39853749d595ad474f3af47c3b",
      "bbd4cc4730c641fdb68c9f76eabd81df",
      "c072d37c64514f1f851cc820115dd184",
      "d339a51e93734d0ea0df7383e18be954",
      "7e531e044d1c46bdad671e1edb8e25e3",
      "34b97e9794f04e93b7731ff7cafdc139",
      "a835b7aacca74da288287e432de705d4",
      "97e19ff39a5541ad86a38dea3fb35ecd",
      "3f9fbe06c96c48708cf31b0c464b577d",
      "dddd172057744927acd041274e5a98b3",
      "adbe78b2ad5049dd8f96a373f0ace919",
      "dcc088839f2044abb9e7cde25f1f3b98",
      "de083c372514413ba36cd2b357e7844a",
      "30a6261b1f5d4066bbea53a0bfdc0bec",
      "869546485e4f48dab941995cf1a00e20",
      "c1298c6450eb4c1d8dc37156acadb8f6",
      "3b36808ed521408c9f15b3ef9c6e48e8",
      "d43aaa4b1e694a87965903bf41930757",
      "11ccf66be21b4c36b0b50c019d4ffe78",
      "8d312d01bda3436cbd144dfcfa0df40a",
      "ae06541c03644503aed15336ea7e2b9b",
      "7edd839ac5264f4faecfa96ce7078ecd",
      "9c48ce8497b7415ba86adddf4bcb3d5b",
      "6139a9f515604326ba1ae0d26da6f2d5",
      "c75066552b3a471281763ba747f60e56",
      "875d1ffb7fbd4a9bb2230b1f229f1569",
      "f0191834215049b1ab99abd03d246860",
      "36c330d510ee436a92dfd90d2c547847",
      "0a3e573d89e049519a4ba654f4582aa6",
      "ba9d2e4f46024ec6835d6a1ffb63f7da",
      "4118676555b5420a8562110304e3813c",
      "9b360b99dc5c48d7aff65da4b029b6a2",
      "8e52ca10126541f295c888aad71f9579",
      "20d741ea21004c81bd74b4c5bd5fb274",
      "6f16308ec6154c2eb2d748c70561115a",
      "708ac349082444ec8ac6e1f01ace5cf4",
      "ce69e05838e04caf9931b0f35f22ce8e",
      "7186f7c5580248f19931afa2210eb8d2",
      "94d1bdf2a480469fbe79ecb358e0227d",
      "edfa5b84ba3b4f91bec1736ee1bf67f3",
      "0f1f3ab98cd147eea611b4493e1ebb78",
      "389eca9d98954ebeb3b2613419affb25",
      "fd13a3071ddd440ba3b034d8bf673a81",
      "6cf7a0c9382548e2807dc67021e21549",
      "0a4114a75c924789a660beb7918382a5",
      "81e26793709b45b583d0f6d51a752aa5",
      "fa1481ae83eb4329a303975c75bc53f2",
      "2ef04b65c35a4164b62a65bcfd53785e",
      "0de5f83d62b6428da5405950dd398f4e",
      "a2da68d62382417880cf323195fc328c",
      "c18983fac96f4b03b3e0cd8e81b3f221",
      "d47c33cca2824b638696c26e71d7f10d",
      "36eb78bdd1414311ad2237314e913b44",
      "44f530f359234e7191637ae1afe3069a",
      "706db472f3ec4f9b9c46c3e991bad974",
      "41d99c4ebd3d4a2fb988ddf919d0df94",
      "4fd7dc808cba4952b59153deb4c1258a",
      "ecee0225f448436a93f4affd19a05989"
     ]
    },
    "executionInfo": {
     "elapsed": 23201,
     "status": "ok",
     "timestamp": 1759694154486,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "OQEbDmC2Q6Vv",
    "outputId": "872d2504-5baf-4890-e1bc-c9eefa13a5ea"
   },
   "outputs": [],
   "source": [
    "# カスタムトレーナーの設定\n",
    "trainer = SoftLabelSFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=lora_config,\n",
    "    temperature=CFG.temperature,\n",
    "    alpha=CFG.alpha,\n",
    "    category_token_ids=new_token_ids,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collator,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1759694154514,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "bq4-w21RQ6a5",
    "outputId": "fa8b8aa7-174a-48f4-dcb3-8ad6e8a84be5"
   },
   "outputs": [],
   "source": [
    "for n, p in trainer.model.named_parameters():\n",
    "    if \"embed_tokens\" in n or \"lm_head\" in n:\n",
    "        print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 7361497,
     "status": "ok",
     "timestamp": 1759701516012,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "z7q9rQZSMjc8",
    "outputId": "ff43805d-26a2-418a-9295-103a905d6fbe"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35254,
     "status": "ok",
     "timestamp": 1759701551271,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "7-RAYBcPR7ss",
    "outputId": "216d2621-d76d-4548-f46b-e8034431062a"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(CFG.output_dir_path + \"/model\")\n",
    "tokenizer.save_pretrained(CFG.output_dir_path + \"/model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
