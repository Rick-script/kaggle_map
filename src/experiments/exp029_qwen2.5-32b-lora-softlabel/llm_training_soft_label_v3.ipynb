{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10685,
     "status": "ok",
     "timestamp": 1760158638500,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "NhOathqKR7sn",
    "outputId": "bf64e56d-9d56-4ed3-dabd-101b9b4406f1"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp029_qwen2.5-32b-lora-softlabel\n",
    "\n",
    "    !pip install -q -U trl==0.23.0\n",
    "    !pip install -q accelerate==1.10.1 bitsandbytes==0.47.0 mpi4py==4.1.0 deepspeed==0.17.6 transformers==4.56.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13494,
     "status": "ok",
     "timestamp": 1760158651997,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "JLsCVK1JR7so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from trl.trainer.sft_trainer import DataCollatorForLanguageModeling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652000,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "sA_IA3vtR7so"
   },
   "outputs": [],
   "source": [
    "# DeepSpeed requires a distributed environment even when only one process is used.\n",
    "# This emulates a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9995\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652002,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "EShEkQPER7sp"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp029_qwen2.5-32b-lora-softlabel_v3\"\n",
    "    model_name = \"Qwen/Qwen2.5-32B-Instruct\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    soft_label_path = f\"{comp_dir_path}/qwen2.5-32b/validation_logprobs_v2_0.pkl\"\n",
    "    output_dir_path = \"output_v3/\"\n",
    "    log_dir_path = \"logs_v3/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 8\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 1e-4\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 32\n",
    "    lora_alpha = 64\n",
    "    lora_dropout = 0.01\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\", \"soft_labels\"]\n",
    "\n",
    "    # ============== ソフトラベル設定 =============\n",
    "    temperature = 1.0\n",
    "    alpha = 0.9\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 26\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "Label: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652003,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "lj_ScryyR7sp"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652004,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "4emKGBEBR7sp"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9WiUp2lR7sp"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652005,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "TokrfpxTR7sq"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652006,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "cKQJwcOhR7sq"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 6 \\)\", r\"\\( 9 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 9 \\)\", r\"\\( 6 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158652008,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "3nk769TSR7sq"
   },
   "outputs": [],
   "source": [
    "def load_soft_labels(soft_label_path: str, all_completions: list) -> dict:\n",
    "    \"\"\"ソフトラベルを読み込み、64カテゴリの確率分布に拡張する\"\"\"\n",
    "    with open(soft_label_path, \"rb\") as f:\n",
    "        soft_labels_raw = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded soft labels for {len(soft_labels_raw)} samples\")\n",
    "\n",
    "    # 64カテゴリの確率分布に拡張\n",
    "    expanded_soft_labels = {}\n",
    "    for idx, soft_label_dict in soft_labels_raw.items():\n",
    "        # 64カテゴリの確率ベクトルを初期化（全て0.0）\n",
    "        full_probs = np.zeros(len(all_completions), dtype=np.float32)\n",
    "\n",
    "        # ソフトラベルに存在するカテゴリの確率を設定\n",
    "        for category, prob in soft_label_dict.items():\n",
    "            if category in all_completions:\n",
    "                cat_idx = all_completions.index(category)\n",
    "                full_probs[cat_idx] = prob\n",
    "\n",
    "        # 確率の合計が1になるように正規化（ソフトラベルの確率の合計が1未満の場合）\n",
    "        prob_sum = np.sum(full_probs)\n",
    "        if prob_sum > 0:\n",
    "            full_probs = full_probs / prob_sum\n",
    "\n",
    "        expanded_soft_labels[idx] = full_probs\n",
    "\n",
    "    return expanded_soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1760158652897,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "P3z0lZ8xR7sq",
    "outputId": "5cd5da82-7eee-460a-be64-bcd1e454e21e"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)\n",
    "\n",
    "# 全てのラベルを取得（64カテゴリ）\n",
    "all_completions = sorted(train[\"completion\"].unique().tolist())\n",
    "print(f\"Total categories: {len(all_completions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1530,
     "status": "ok",
     "timestamp": 1760158654429,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "KvOc_xOdR7sr",
    "outputId": "d7da8182-1db7-4b4c-a6b7-127e31533270"
   },
   "outputs": [],
   "source": [
    "# ソフトラベルの読み込み\n",
    "soft_labels = load_soft_labels(CFG.soft_label_path, all_completions)\n",
    "\n",
    "# trainデータにソフトラベルを追加\n",
    "train[\"soft_labels\"] = train.index.map(lambda idx: soft_labels.get(idx, np.zeros(len(all_completions), dtype=np.float32)))\n",
    "\n",
    "print(f\"Added soft labels for {len(train)} samples\")\n",
    "print(f\"Example soft label shape: {train['soft_labels'].iloc[0].shape}\")\n",
    "print(f\"Example soft label sum: {np.sum(train['soft_labels'].iloc[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760158654438,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "8M99HHsKR7sr",
    "outputId": "2ca2046a-df22-454f-8852-a0c1db938dcf"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])\n",
    "print(train[\"completion\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 235,
     "status": "ok",
     "timestamp": 1760158654674,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vjZUydQsR7sr"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].sample(frac=1, random_state=CFG.seed).reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xm0kpFPR7sr"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760158654681,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "oWCGcu9IR7sr"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c94dcfc6260342718fe121dac9e540b0",
      "480272158ba34bc9a49e5cd1c27eee23",
      "c202051b8448443f94239bc4ff29f083",
      "4194b3a57eeb4c7b909e21b76a138d1f",
      "e2940e5313894abb9879590e5edb4d33",
      "6cf40e880267452fb11bc7afe2d2ea66",
      "f2c05965688b4f1283d56bfe1aa9e0d5",
      "7b163692628a473d9dab8518bd5504f9",
      "38e0d4e4d5764a34ac1749c8b6455188",
      "b15e6020a3814e1f8cb340517dae88f9",
      "35668fc98a6446dfb56320db625ddbcd"
     ]
    },
    "executionInfo": {
     "elapsed": 106172,
     "status": "ok",
     "timestamp": 1760158760854,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vnxnv8WdR7sr",
    "outputId": "55679940-f8fe-45ac-cae6-590711c0affa"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158760858,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Vb3n77IwR7sr"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1760158760985,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "XQr9BrseR7sr",
    "outputId": "f5d2d413-791c-4ba5-b7e9-913e41618317"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "executionInfo": {
     "elapsed": 4719,
     "status": "ok",
     "timestamp": 1760158765706,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Xkr1qpKLR7sr",
    "outputId": "52e2a284-091b-4a3d-f98c-76c705bb5a7f"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1760158766728,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gH24xZA-R7sr"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero1.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": \"auto\"\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "            \"pin_memory\": true\n",
    "        }\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4839,
     "status": "ok",
     "timestamp": 1760158771570,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "hUNbpQCXeg6F"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=1,\n",
    "    # save_steps=0.2,\n",
    "    # save_total_limit=1,\n",
    "    # metric_for_best_model=\"map@3\",\n",
    "    # greater_is_better=True,\n",
    "    # load_best_model_at_end=True,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    "    completion_only_loss=True,\n",
    "    deepspeed=\"ds_config_zero1.json\",\n",
    "    dataset_num_proc=8,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1760158771582,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "nndt9wRoR7sr"
   },
   "outputs": [],
   "source": [
    "# 追加済みの全ラベルをIDに\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(all_completions)\n",
    "\n",
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    "    modules_to_save=[\"lm_head\"],\n",
    "    trainable_token_indices={\"embed_tokens\": new_token_ids}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxALZ_PTR7sr"
   },
   "source": [
    "### カスタムトレーナー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1760158771590,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "QrBGkcslLvDj"
   },
   "outputs": [],
   "source": [
    "class SoftLabelCollator:\n",
    "    \"soft_labelsをcustom_trainerに渡す\"\n",
    "    def __init__(self, base_collator):\n",
    "        self.base_collator = base_collator\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        has_soft_labels = \"soft_labels\" in examples[0]\n",
    "        if has_soft_labels:\n",
    "            soft_labels = [ex[\"soft_labels\"] for ex in examples]\n",
    "        else:\n",
    "            soft_labels = None\n",
    "\n",
    "        # 既存のcollatorを通す\n",
    "        batch = self.base_collator(examples)\n",
    "\n",
    "        # soft_labels をそのまま追加\n",
    "        if has_soft_labels:\n",
    "            batch[\"soft_labels\"] = soft_labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760158771592,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gqOAqy-fz0KF"
   },
   "outputs": [],
   "source": [
    "class SoftLabelSFTTrainer(SFTTrainer):\n",
    "    \"\"\"ソフトラベル学習に対応したカスタムSFTTrainer\"\"\"\n",
    "\n",
    "    def __init__(self, temperature=1.0, alpha=0.7, category_token_ids=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.category_token_ids = (torch.tensor(category_token_ids) if category_token_ids else None)\n",
    "        self.kl_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"ソフトラベルとハードラベルの混合損失を計算\"\"\"\n",
    "\n",
    "        # ソフトラベル取得\n",
    "        soft_labels = inputs.pop(\"soft_labels\", None)\n",
    "\n",
    "        # 通常のforward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # ソフトラベルとカテゴリトークンが指定されている場合のみ特殊処理\n",
    "        # ------------------------------------------------------------\n",
    "        if soft_labels is not None and self.category_token_ids is not None:\n",
    "            labels = inputs.get(\"labels\", None)\n",
    "            if labels is None:\n",
    "                return outputs.loss if not return_outputs else (outputs.loss, outputs)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            category_positions = []\n",
    "            actual_category_labels = []\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # カテゴリトークンの位置を特定し、予測すべき位置を抽出\n",
    "            # ------------------------------------------------------------\n",
    "            for b in range(batch_size):\n",
    "                sample_labels = labels[b]\n",
    "                cat_mask = torch.zeros_like(sample_labels, dtype=torch.bool)\n",
    "\n",
    "                for cat_id in self.category_token_ids:\n",
    "                    cat_mask |= (sample_labels == cat_id.to(sample_labels.device))\n",
    "\n",
    "                cat_positions = torch.nonzero(cat_mask, as_tuple=True)[0]\n",
    "\n",
    "                if len(cat_positions) > 0:\n",
    "                    # 最初のカテゴリトークンの1つ前を予測位置とする\n",
    "                    pos = max(cat_positions[0].item() - 1, 0)\n",
    "                    actual_category_labels.append(sample_labels[cat_positions[0]].item())\n",
    "                else:\n",
    "                    # カテゴリトークンが見つからない場合、最後の有効トークンを使う\n",
    "                    print(\"カテゴリトークンが見つかりません\")\n",
    "                    valid_mask = sample_labels != -100\n",
    "                    valid_positions = torch.nonzero(valid_mask, as_tuple=True)[0]\n",
    "                    if len(valid_positions) > 0:\n",
    "                        pos = valid_positions[-2].item() if len(valid_positions) > 1 else 0\n",
    "                        actual_category_labels.append(sample_labels[valid_positions[-1]].item())\n",
    "                    else:\n",
    "                        pos = logits.size(1) - 1\n",
    "                        actual_category_labels.append(-100)\n",
    "\n",
    "                category_positions.append(pos)\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 各サンプルの対象位置のlogitsを取得\n",
    "            # ------------------------------------------------------------\n",
    "            selected_logits = torch.stack([\n",
    "                logits[i, pos, :] for i, pos in enumerate(category_positions)\n",
    "            ])\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # デバッグ出力\n",
    "            # ------------------------------------------------------------\n",
    "            # if self.state.global_step % 10 == 0:\n",
    "            #     with torch.no_grad():\n",
    "            #         print(f\"\\n{'='*80}\")\n",
    "            #         print(f\"[Step {self.state.global_step}] Token predictions at completion position:\")\n",
    "\n",
    "            #         for i in range(min(3, batch_size)):\n",
    "            #             print(f\"\\n  Sample {i} (position={category_positions[i]}):\")\n",
    "\n",
    "            #             # --- (1) 全語彙からのトップ5 ---\n",
    "            #             all_probs = F.softmax(selected_logits[i], dim=-1)\n",
    "            #             top5_probs, top5_indices = torch.topk(all_probs, k=5, dim=-1)\n",
    "\n",
    "            #             print(\"    Top-5 from ALL vocabulary:\")\n",
    "            #             for idx, prob in zip(top5_indices, top5_probs):\n",
    "            #                 token_id = idx.item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"token_{token_id}\"\n",
    "            #                 )\n",
    "            #                 marker = \" [CAT]\" if token_id in self.category_token_ids else \"\"\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}{marker}\")\n",
    "\n",
    "            #             # --- (2) カテゴリトークンのみのトップ5 ---\n",
    "            #             cat_logits = selected_logits[i][self.category_token_ids.to(selected_logits.device)]\n",
    "            #             cat_probs = F.softmax(cat_logits, dim=-1)\n",
    "            #             top5_cat_probs, top5_cat_indices = torch.topk(\n",
    "            #                 cat_probs, k=min(5, cat_probs.size(-1)), dim=-1\n",
    "            #             )\n",
    "\n",
    "            #             print(\"    Top-5 CATEGORY tokens (Model Prediction):\")\n",
    "            #             for idx, prob in zip(top5_cat_indices, top5_cat_probs):\n",
    "            #                 token_id = self.category_token_ids[idx].item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"cat_{token_id}\"\n",
    "            #                 )\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "            #             # --- (3) ソフトラベルのトップ5 ---\n",
    "            #             soft_label_tensor = torch.as_tensor(\n",
    "            #                 soft_labels[i], dtype=torch.float32\n",
    "            #             )\n",
    "            #             top5_soft_probs, top5_soft_indices = torch.topk(\n",
    "            #                 soft_label_tensor, k=min(5, len(soft_label_tensor))\n",
    "            #             )\n",
    "\n",
    "            #             print(\"    Top-5 SOFT LABELS (Target Distribution):\")\n",
    "            #             for idx, prob in zip(top5_soft_indices, top5_soft_probs):\n",
    "            #                 token_id = self.category_token_ids[idx].item()\n",
    "            #                 token_str = (\n",
    "            #                     self.processing_class.decode([token_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"soft_{token_id}\"\n",
    "            #                 )\n",
    "            #                 print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "            #             # --- (4) 正解ラベルを表示 ---\n",
    "            #             if i < len(actual_category_labels) and actual_category_labels[i] != -100:\n",
    "            #                 true_label_id = actual_category_labels[i]\n",
    "            #                 true_label_str = (\n",
    "            #                     self.processing_class.decode([true_label_id]).strip()\n",
    "            #                     if hasattr(self.processing_class, \"decode\")\n",
    "            #                     else f\"label_{true_label_id}\"\n",
    "            #                 )\n",
    "\n",
    "            #                 if true_label_id in self.category_token_ids:\n",
    "            #                     cat_index = (self.category_token_ids == true_label_id).nonzero(as_tuple=True)[0]\n",
    "            #                     if len(cat_index) > 0:\n",
    "            #                         true_prob = cat_probs[cat_index[0]].item()\n",
    "            #                         print(f\"    TRUE LABEL: {true_label_str} (prob={true_prob:.4f})\")\n",
    "            #                     else:\n",
    "            #                         print(f\"    TRUE LABEL: {true_label_str}\")\n",
    "            #                 else:\n",
    "            #                     print(f\"    TRUE LABEL: {true_label_str} [NOT A CATEGORY TOKEN]\")\n",
    "            #             else:\n",
    "            #                 print(\"    TRUE LABEL: Not found\")\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # ソフトラベル損失（KL Divergence）の計算\n",
    "            # ------------------------------------------------------------\n",
    "            # 全語彙サイズを取得\n",
    "            vocab_size = selected_logits.size(-1)\n",
    "\n",
    "            # 全語彙に対するソフトラベルテンソルを初期化（全て0）\n",
    "            soft_labels_full = torch.zeros(batch_size, vocab_size, device=selected_logits.device)\n",
    "\n",
    "            # カテゴリトークンの位置にソフトラベルの値を設定\n",
    "            for i in range(batch_size):\n",
    "                for j, cat_id in enumerate(self.category_token_ids):\n",
    "                    soft_labels_full[i, cat_id.item()] = soft_labels[i][j]\n",
    "\n",
    "            # 全語彙に対してlog_softmaxを計算\n",
    "            log_probs = F.log_softmax(selected_logits / self.temperature, dim=-1)\n",
    "\n",
    "            # nn.KLDivLossを使用（全語彙に対して）\n",
    "            kl_loss = self.kl_criterion(log_probs, soft_labels_full)\n",
    "            kl_loss *= self.temperature ** 2\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 損失の混合\n",
    "            # ------------------------------------------------------------\n",
    "            hard_loss = outputs.loss if outputs.loss is not None else 0\n",
    "            total_loss = (1 - self.alpha) * hard_loss + self.alpha * kl_loss\n",
    "\n",
    "            # if self.state.global_step % 10 == 0:\n",
    "            #     print(f\"\\n  Losses - Hard: {hard_loss.item():.4f}, KL: {kl_loss.item():.4f}, Total: {total_loss.item():.4f}\")\n",
    "            #     print('=' * 80)\n",
    "\n",
    "        else:\n",
    "            # ソフトラベルを使用しない通常損失\n",
    "            total_loss = outputs.loss\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhVu51fNULHR"
   },
   "source": [
    "### 評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760158771592,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "LAxhktY2UKHP"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位5件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 5\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760158771593,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1ArxPkjxUKJz"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO2rpJN6Us3V"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760158771594,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "SX2rWXZ_Q6TZ"
   },
   "outputs": [],
   "source": [
    "# collatorの定義\n",
    "base = DataCollatorForLanguageModeling(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    completion_only_loss=True,\n",
    "    padding_free=False\n",
    ")\n",
    "collator = SoftLabelCollator(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "1e7c6790ed6f440d9d4b75714dc2f37b",
      "0c023b56de8f436f89b370a771d0a94c",
      "86db16e26fab42098a499f7b3c47428e",
      "4dfb18d609c041a6a8c4b43269a2a09a",
      "83bf38429f29451c8fe45b6086c14223",
      "70c1c483102548eb84fbc5af6cff7d31",
      "6a868ec9601f49478d339e4856b18bb8",
      "3bb3a81766324311b2920ae48b7963fd",
      "e7b0dc602eee4d99bd90d95511e93350",
      "c73e665704a04e87a06c9af1f105561d",
      "20ca89718e0248be9b23941ed94b5d6d",
      "0088372bcaa745ee89a2de31fa2fbf92",
      "bcee1d2237fc4cea85d9e0bb2386e48e",
      "cd8af2f99bdb4948b43faf70d37e5bd4",
      "0f31c88a5a4a4797bf16193d1794a8fb",
      "2aff73e63a4b4777ad1fcab36e6f626f",
      "cc2a1ad252934fb4a1819f7c5235e08f",
      "3b0c3fca5d754b99ad945332e72dad50",
      "0d6243d8a8d943a896c4d0fd7c5f3930",
      "891e94eb6d4a4a0c8f72d467d0d7e435",
      "26929c302ca747c3b189a9054baad08d",
      "17ba8f56b1b94ebd81288a307fa4b129",
      "a28df3779942462c8bd3fbc9a63e012a",
      "88beca2d91df4fc0a3949b52d9100347",
      "48fba1531be94265ae8fb0fc65255fcb",
      "657f379e040c45119397142f3d4915b2",
      "bfe7a49dbd474f98b42713b2fc6f1aed",
      "ed928812a9a14ce0bec9d696b7962704",
      "5fc1685a4afe446d87605841be97b8a3",
      "0d3254f60f394c6fad045b3e97482bb3",
      "e941bf0a9ea840f484afc9df6686c610",
      "258e9e5f63b44a47a0dfab7cdb041170",
      "57ba31ddfd8b4596a126fad94a2405f8",
      "fa7a3753474d4bcca89a929c697545fa",
      "775473bc5191440eb2eee7baaee7c91e",
      "6108b18f97784da9993197d7c7b2dbd0",
      "e05c0ca6028e4922a993da15c0d5908a",
      "a15eae01cd484434938268cbb9d78886",
      "5cf70bdae62746819fac197266d6741e",
      "8cd27acfa93841d7a5f920050758127c",
      "07b9b97b4df843f08380c8d2b630f244",
      "52e7a7147c7a4921a1dec939eb761acf",
      "53baead3928c452f9d2fca851b292a59",
      "b0ddb499f5ca4ff2bba66b6d16bcb38b",
      "279e3c4ebe974a0a9505d821c57f68dd",
      "11f25837d99c41a29c7d13b6406b44ac",
      "0b11684cb0d24fb69507f93e354ee2ef",
      "afef2c9ecb184e2a9f4f29008cc3b705",
      "c0d9255713c749d683f96c9eadc392db",
      "3d27505c0c6f4a8cafeda53e41d363bf",
      "255f0d9ce50b4191a0ff1f0f5ead4595",
      "4348bccc2ae54af9be895ad45d1f64c1",
      "14c9cf2cc8cb49aa8a820c1ac1be41f0",
      "6b63ff25b39a403ebe6eda4e8cfa4ae3",
      "72a0384a4d564b5e8532dd3accd72f2c",
      "677466a2fcb4427c8e01de111826d3b7",
      "fef9724515ad4ad28a407f12c1d2536e",
      "62d9f51c28cd47eca6278098733927b6",
      "4dd9a105d2634b5fb91f10e51189bd82",
      "478d1ad820e74815a74a15a1409baad4",
      "426abbfe7c3540f0a05c0eafeabcb2ef",
      "727e3d6a9af647e1bb5317d2e09e4be9",
      "269a92d745a54d70a67843741fe95591",
      "9f19b86bf75c42d588b302d051b3c0f2",
      "507839567447488988f38cb56b44c205",
      "fa5b3c99bd5b41548a738fdc70854aae"
     ]
    },
    "executionInfo": {
     "elapsed": 21781,
     "status": "ok",
     "timestamp": 1760158793376,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "OQEbDmC2Q6Vv",
    "outputId": "f00ded73-aa84-48c8-b013-1196899084b2"
   },
   "outputs": [],
   "source": [
    "# カスタムトレーナーの設定\n",
    "trainer = SoftLabelSFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=lora_config,\n",
    "    temperature=CFG.temperature,\n",
    "    alpha=CFG.alpha,\n",
    "    category_token_ids=new_token_ids,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collator,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1760158793399,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "bq4-w21RQ6a5",
    "outputId": "5f3249a5-b295-49f1-f36c-1de2f0ba1897"
   },
   "outputs": [],
   "source": [
    "for n, p in trainer.model.named_parameters():\n",
    "    if \"embed_tokens\" in n or \"lm_head\" in n:\n",
    "        print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 13230823,
     "status": "ok",
     "timestamp": 1760172024223,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "z7q9rQZSMjc8",
    "outputId": "a5782b16-ae9b-47f0-b372-758968ee0a3c"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163119,
     "status": "ok",
     "timestamp": 1760172187344,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "7-RAYBcPR7ss",
    "outputId": "ece8ac76-050c-4543-c52f-6caae7eb8899"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(CFG.output_dir_path + \"/model\")\n",
    "tokenizer.save_pretrained(CFG.output_dir_path + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 600350,
     "status": "ok",
     "timestamp": 1760172787696,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "L2F6VPtdNe_S",
    "outputId": "2748f6c8-1b44-4209-a081-2125c58906a6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from google.colab import runtime\n",
    "\n",
    "def disconnect_runtime_after_timeout(timeout=3600):\n",
    "    print(f\"ランタイムが{timeout // 60}分後に自動で切断されます。\")\n",
    "    time.sleep(timeout)\n",
    "    print(\"ランタイムを切断します...\")\n",
    "    runtime.unassign()\n",
    "\n",
    "disconnect_runtime_after_timeout(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760172787699,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "29m1N_uVNfh9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
