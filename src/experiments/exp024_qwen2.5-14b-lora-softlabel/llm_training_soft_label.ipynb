{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57959,
     "status": "ok",
     "timestamp": 1760030379595,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "NhOathqKR7sn",
    "outputId": "6e680b4b-056f-4a3e-a57a-5d5e560b2516"
   },
   "outputs": [],
   "source": [
    "# Google Colabでの設定\n",
    "google_colab = True\n",
    "\n",
    "if google_colab:\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    # ディレクトリ移動\n",
    "    %cd /content/drive/MyDrive/Python/kaggle_map/src/exp024_qwen2.5-14b-lora-softlabel\n",
    "\n",
    "    !pip install -q -U trl==0.23.0\n",
    "    !pip install -q accelerate==1.10.1 bitsandbytes==0.47.0 mpi4py==4.1.0 deepspeed==0.17.6 transformers==4.56.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16359,
     "status": "ok",
     "timestamp": 1760030395955,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "JLsCVK1JR7so"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizer,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from trl.trainer.sft_trainer import DataCollatorForLanguageModeling\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030395958,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "sA_IA3vtR7so"
   },
   "outputs": [],
   "source": [
    "# DeepSpeed requires a distributed environment even when only one process is used.\n",
    "# This emulates a launcher in the notebook\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9995\"  # modify if RuntimeError: Address already in use\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030395960,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "EShEkQPER7sp"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"実験設定管理クラス\"\"\"\n",
    "\n",
    "    # ============== 実験情報 =============\n",
    "    comp_name = \"kaggle_map\"\n",
    "    exp_name = \"exp024_qwen2.5-14b-lora-softlabel\"\n",
    "    model_name = \"Qwen/Qwen2.5-14B-Instruct\"\n",
    "\n",
    "    # ============== ファイルパス設定 =============\n",
    "    comp_dir_path = \"../../kaggle/input/\"\n",
    "    comp_dataset_path = f\"{comp_dir_path}/map-charting-student-math-misunderstandings/\"\n",
    "    soft_label_path = f\"{comp_dir_path}/qwen2.5-14b/validation_logprobs_merged.pkl\"\n",
    "    output_dir_path = \"output/\"\n",
    "    log_dir_path = \"logs/\"\n",
    "\n",
    "    # ============== モデル設定 =============\n",
    "    max_len = 256\n",
    "    num_train_epochs = 2\n",
    "    per_device_train_batch_size = 8\n",
    "    gradient_accumulation_steps = 2\n",
    "    per_device_eval_batch_size = 8\n",
    "    optim_type = \"adamw_torch\"\n",
    "    learning_rate = 8e-5\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "    warmup_ratio = 0.03\n",
    "    weight_decay = 0.01\n",
    "\n",
    "    lora_r = 64\n",
    "    lora_alpha = 128\n",
    "    lora_dropout = 0.01\n",
    "    lora_bias = \"none\"\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "    task_type = \"CAUSAL_LM\"\n",
    "\n",
    "    cols = [\"prompt\", \"completion\", \"soft_labels\"]\n",
    "\n",
    "    # ============== ソフトラベル設定 =============\n",
    "    temperature = 1.0\n",
    "    alpha = 0\n",
    "\n",
    "    # ============== その他設定 =============\n",
    "    seed = 42\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ============== プロンプト設定 =============\n",
    "    prompt_format = \"\"\"You are a specialist in identifying the types of misunderstandings that arise from students' answers to math problems.\n",
    "Based on the information provided below, please determine what kind of misunderstanding the student has.\n",
    "\n",
    "Question: {QuestionText}\n",
    "Answer: {MC_Answer}\n",
    "Correct: {Correct}\n",
    "Student Explanation: {StudentExplanation}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030395962,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "lj_ScryyR7sp"
   },
   "outputs": [],
   "source": [
    "# 乱数固定\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.output_dir_path, cfg.log_dir_path]:\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "def cfg_init(cfg):\n",
    "    set_seed(cfg.seed)\n",
    "    make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1760030395964,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "4emKGBEBR7sp"
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9WiUp2lR7sp"
   },
   "source": [
    "## データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030395966,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "TokrfpxTR7sq"
   },
   "outputs": [],
   "source": [
    "def add_folds_by_qid_cat_misc(df, n_splits=5, random_state=42, fallback=\"pair\"):\n",
    "    s_qid = df[\"QuestionId\"].astype(str).fillna(\"NA\")\n",
    "    s_cat = df[\"Category\"].astype(str).fillna(\"NA\")\n",
    "    s_misc = df[\"Misconception\"].astype(str).fillna(\"NA\")\n",
    "\n",
    "    y_triple = s_qid + \"|\" + s_cat + \"|\" + s_misc\n",
    "    y_pair = s_cat + \"|\" + s_misc\n",
    "\n",
    "    cnt = y_triple.value_counts()\n",
    "    if (cnt < n_splits).any():\n",
    "        if fallback == \"pair\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, y_pair, y_triple)\n",
    "        elif fallback == \"category\":\n",
    "            rare = y_triple.map(cnt) < n_splits\n",
    "            y = np.where(rare, s_cat, y_triple)\n",
    "        elif fallback == \"none\":\n",
    "            y = y_triple\n",
    "        else:\n",
    "            raise ValueError(\"fallback は 'pair' / 'category' / 'none' のいずれかにしてください。\")\n",
    "    else:\n",
    "        y = y_triple\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    folds = np.full(len(df), -1, dtype=int)\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(np.zeros(len(df)), y)):\n",
    "        folds[val_idx] = fold\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"fold\"] = folds\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760030395967,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "cKQJwcOhR7sq"
   },
   "outputs": [],
   "source": [
    "def wrong_corrections(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"既知の誤りを修正する\"\"\"\n",
    "    false_to_true_ids = [12878, 12901, 13876, 14089, 14159, 14185]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(false_to_true_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 6 \\)\", r\"\\( 9 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "\n",
    "    true_to_false_ids = [14280, 14305, 14321, 14335, 14338,  14352, 14355, 14403, 14407, 14412, 14413, 14418]\n",
    "    df[\"MC_Answer\"] = np.where(\n",
    "        df[\"row_id\"].isin(true_to_false_ids),\n",
    "        df[\"MC_Answer\"].str.replace(r\"\\( 9 \\)\", r\"\\( 6 \\)\"),\n",
    "        df[\"MC_Answer\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_duplicate_misc(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"誤りのある誤答ラベルを修正する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].replace({\"Wrong_Fraction\": \"Wrong_fraction\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_completion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"completion列を作成する\"\"\"\n",
    "    df[\"Misconception\"] = df[\"Misconception\"].fillna(\"NA\")\n",
    "    df[\"completion\"] = df[\"Category\"] + \":\" + df[\"Misconception\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_correct(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"正答かどうかのフラグを追加する\"\"\"\n",
    "    idx = df.apply(lambda row: row[\"Category\"].split(\"_\")[0], axis=1) == \"True\"\n",
    "    correct = df.loc[idx].copy()\n",
    "    correct[\"count\"] = correct.groupby([\"QuestionId\", \"MC_Answer\"]).MC_Answer.transform(\"count\")\n",
    "    correct = correct.sort_values(\"count\", ascending=False)\n",
    "    correct = correct.drop_duplicates([\"QuestionId\"])\n",
    "    correct = correct[[\"QuestionId\", \"MC_Answer\"]]\n",
    "    correct[\"is_correct\"] = 1\n",
    "\n",
    "    df = df.merge(correct, on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\n",
    "    df[\"is_correct\"] = df[\"is_correct\"].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_input(row) -> str:\n",
    "    \"\"\"入力テキストのフォーマット\"\"\"\n",
    "    return CFG.prompt_format.format(\n",
    "        QuestionText=row[\"QuestionText\"],\n",
    "        MC_Answer=row[\"MC_Answer\"],\n",
    "        Correct=\"Yes\" if row[\"is_correct\"] else \"No\",\n",
    "        StudentExplanation=row[\"StudentExplanation\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760030395968,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "3nk769TSR7sq"
   },
   "outputs": [],
   "source": [
    "def load_soft_labels(soft_label_path: str, all_completions: list) -> dict:\n",
    "    \"\"\"ソフトラベルを読み込み、64カテゴリの確率分布に拡張する\"\"\"\n",
    "    with open(soft_label_path, \"rb\") as f:\n",
    "        soft_labels_raw = pickle.load(f)\n",
    "\n",
    "    print(f\"Loaded soft labels for {len(soft_labels_raw)} samples\")\n",
    "\n",
    "    # 64カテゴリの確率分布に拡張\n",
    "    expanded_soft_labels = {}\n",
    "    for idx, soft_label_dict in soft_labels_raw.items():\n",
    "        # 64カテゴリの確率ベクトルを初期化（全て0.0）\n",
    "        full_probs = np.zeros(len(all_completions), dtype=np.float32)\n",
    "\n",
    "        # ソフトラベルに存在するカテゴリの確率を設定\n",
    "        for category, prob in soft_label_dict.items():\n",
    "            if category in all_completions:\n",
    "                cat_idx = all_completions.index(category)\n",
    "                full_probs[cat_idx] = prob\n",
    "\n",
    "        # 確率の合計が1になるように正規化（ソフトラベルの確率の合計が1未満の場合）\n",
    "        prob_sum = np.sum(full_probs)\n",
    "        if prob_sum > 0:\n",
    "            full_probs = full_probs / prob_sum\n",
    "\n",
    "        expanded_soft_labels[idx] = full_probs\n",
    "\n",
    "    return expanded_soft_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2670,
     "status": "ok",
     "timestamp": 1760030398639,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "P3z0lZ8xR7sq",
    "outputId": "7a9ca870-c250-4dc0-81b2-60f7bae2f57d"
   },
   "outputs": [],
   "source": [
    "# 学習データの読み込み\n",
    "train = pd.read_csv(f\"{CFG.comp_dataset_path}/train.csv\")\n",
    "\n",
    "# Fold分割\n",
    "train = add_folds_by_qid_cat_misc(train, n_splits=5, random_state=42, fallback=\"pair\")\n",
    "\n",
    "# 既知の誤り修正\n",
    "train = wrong_corrections(train)\n",
    "\n",
    "# 重複するMisconceptionの統一\n",
    "train = replace_duplicate_misc(train)\n",
    "\n",
    "# completion列の作成\n",
    "train = make_completion(train)\n",
    "\n",
    "# 正解フラグの作成\n",
    "train = add_is_correct(train)\n",
    "\n",
    "# 入力プロンプトの作成\n",
    "train[\"prompt\"] = train.apply(format_input, axis=1)\n",
    "\n",
    "# 全てのラベルを取得（64カテゴリ）\n",
    "all_completions = sorted(train[\"completion\"].unique().tolist())\n",
    "print(f\"Total categories: {len(all_completions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1760030400764,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "KvOc_xOdR7sr",
    "outputId": "37baad6e-71ac-43d6-cd44-6a0e3a112ec6"
   },
   "outputs": [],
   "source": [
    "# ソフトラベルの読み込み\n",
    "soft_labels = load_soft_labels(CFG.soft_label_path, all_completions)\n",
    "\n",
    "# trainデータにソフトラベルを追加\n",
    "train[\"soft_labels\"] = train.index.map(lambda idx: soft_labels.get(idx, np.zeros(len(all_completions), dtype=np.float32)))\n",
    "\n",
    "print(f\"Added soft labels for {len(train)} samples\")\n",
    "print(f\"Example soft label shape: {train['soft_labels'].iloc[0].shape}\")\n",
    "print(f\"Example soft label sum: {np.sum(train['soft_labels'].iloc[0]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1760030400810,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "8M99HHsKR7sr",
    "outputId": "20f5688b-9a26-4d6b-f250-4643fc9cbe16"
   },
   "outputs": [],
   "source": [
    "# プロンプトの表示\n",
    "print(train[\"prompt\"].values[0])\n",
    "print(train[\"completion\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1760030401056,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vjZUydQsR7sr"
   },
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_df = train[train[\"fold\"] != 0].sample(frac=1, random_state=CFG.seed).reset_index(drop=True)\n",
    "val_df = train[train[\"fold\"] == 0].reset_index(drop=True)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[CFG.cols], preserve_index=False)\n",
    "val_ds = Dataset.from_pandas(val_df[CFG.cols], preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xm0kpFPR7sr"
   },
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030401059,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "oWCGcu9IR7sr"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561,
     "referenced_widgets": [
      "dcb7317ca02246ecb94a59f8e77fee81",
      "b555adced883473391b386faaa3381fe",
      "59d6d7506cfc4787ac500ccfb6050eb7",
      "b329380e0eb247ed8c0ceeedab6d4ba2",
      "d31575c0da0f4cbebe2f18e67c0b1139",
      "3c383cfea40d42d1a5a128eaf4e424c7",
      "c5c0545dd9454a43b016a25faab32626",
      "a53fbaa81d2d433980ff01da8f3caee9",
      "e4168b3697b748b18cfdd0988cd5fd44",
      "1b1abbeaa68345fe8b89a2639378c437",
      "b9ceba92b77d478ebafe07438fcb9bd5",
      "0e6236f43f1444e58bf4504d383f6b4f",
      "8abd23fd0de64d228da94308470d461e",
      "55ae6e52958b40a7976e9afd7a47128c",
      "f5185d3ca31f4515a82fa85d7e7a148f",
      "32313f1e13594bc39cc3c834f67565ed",
      "677b219ecd824b4a8abbccf3949d5223",
      "9009e442db274b31b59d97130391d9e6",
      "40f8901ba9b6459ab73b33ac7e8d8fb6",
      "fea4cd91125b4d1ebb9d85fb7d34bb32",
      "0c51684339334f93aa108ac97b316348",
      "0d8b090ccb934e11ad178a4800f0e4e4",
      "5c8af8b9e1b94659a5732c4cc9b8048a",
      "81ea8ec14c8d41d59ad7c7066c9071d1",
      "a35cd12e940648b394fb59d4695c690d",
      "0c5c209ece1c417d87eb0518ab5ebfe8",
      "bb5d0229800940eabf587ccdda7e73e3",
      "6d4e9215621e4390a316cc7515209a26",
      "698348d15f814643967853e4b5f02713",
      "d849998b840844dea9f0bc4793481958",
      "87f6f976d39942d9bfe3da80ba152dcc",
      "60f6b75488324b9283e453ef4831db1a",
      "71cd6621fd6a4c618841e9612331b4a5",
      "3196ba54139440d9b07ba7ce644163e8",
      "6ca17cc742a0498ebc311245c1df7dc7",
      "6604c4cf34c04a75bb8ca46cf4d1bd81",
      "52921081b80841d89e492af46181ab7c",
      "6fe84f9a565d42ca9fb9763e430080dd",
      "0b18ca06a7094870a5f20b7e42857bb1",
      "8a23bd7f7afd4b7d9fb5db80c3c1c936",
      "d80227b6f70845f8967619f64fd04174",
      "2f941623c814435aa0ff1211aed0526e",
      "a25035e42efa45c3a05448e6a5489dfc",
      "3953efc143ae43d0a6b62bf1018b2b7e",
      "4a8e3fb00dfb45febf5076ad72f0e78d",
      "5b404231a61246ad8e7cfa788183d087",
      "43b97c17cc26430bbc0ea745be620ba1",
      "8cec9af19f774b2aa8610a819d883d7f",
      "2d2a92ba9b0b485da2342d8807e2375a",
      "30590c1b729c445b80736dbbd1f6c862",
      "9adb0059236847db85a894fdf6c763b6",
      "8d4032b03971416b92c35c1d60bf75ee",
      "c2fd9e4c6ac5416da9cb5436bfa9a21e",
      "6af8f57bec6b4eedb7e68628ae3f634e",
      "caf24eae894245149f376634f9f5b94d",
      "d2c9bf91ef02425ca8c8d3505da7408a",
      "a7b37cbd0ded4beaae07736903d84a14",
      "8b716143509c4a118c0bc76737e2e613",
      "07742a2b3d0347d8bdcc37c15d5172c8",
      "c856aed145504e948c5ed7a681ef59fc",
      "4436f6a648bf4d0a87314c2321120762",
      "e532eaf03aad43808c16e1137a728966",
      "6e80319706ad4c359c0fafdf224f056b",
      "09c6f3fe4f0147f3aedc3307a2599b84",
      "2cd7930ef8bb4535a92f56e91625997f",
      "1f30d64c64e44028a034e6148fa0c8b5",
      "4b1dd8b272e84d48bfa093e4d567c105",
      "cb8175bd89fd41048bad528e3d04c904",
      "0e8e92a24beb4d299d3f639daae036da",
      "9c28674a3a05405cb6076d27ce22d7f6",
      "3be83ada4a274fa3acca4364e887aa26",
      "e8c781c49f7c4c01ab776ff4abaa3fe9",
      "b84c53de3af34a3e8d62768ae5f25836",
      "8928a24b403f4ecdbea16bc0224ba9e1",
      "f6f5f66f63414a68a8942a911da70e22",
      "8d48dc37cdde421db6d850c91fa514bd",
      "7f033a8b634143dfb8916df20ebfb2d7",
      "ba93fac5213e402e924362468d4b6535",
      "569524ff8f30418c8e66ff5acb1f95de",
      "d9b83767ab8d4f12b5d53a1019ddf8ec",
      "5619b04979f84a55a54e748795dc564c",
      "cee31ab304204bf7a8093f2f8a71a142",
      "4cd0e988d3114a94adf0359be003b013",
      "6c00c6015f2c439180c28f9e81c36b08",
      "f635f65c8e974de5a9b39ed84a41d41e",
      "6355af4dc8a845d98325bf7b6269f9e8",
      "100d689b7f274e808368fb0b9a991f48",
      "27507ab61aad45549db106e56eba0c42",
      "9194d794aac04a828dac08e2ab869f88",
      "50ab998d63c040d58dab001bbbf6a740",
      "51fed59106e843409f9485d9c0bdd844",
      "33bbfd201a124c09a70f68c1078fde5d",
      "56c0c9f83c36401a8827854110cddc8b",
      "e25c5d002c474c44ba3d84e45f0a9def",
      "50090673e55443168c510573ff430cf5",
      "5b055e05a88341b29cedaa89b756d567",
      "7054df05d268448cb630ceff5ab7acbc",
      "02b6ca79ce264e6eacdff3b6260e7fcf",
      "d46e2efa2c594c0ab489670cf419acb4",
      "3c843b9d58eb4d619a293c6a4ccce966",
      "f1dd49dbde2340cc944569baa0c8012d",
      "39e3193b3b80441babbb43dde9ff4ef4",
      "8fb8879f50de4e3b89942e856fe7e393",
      "757dc492b6f644428494ccee856f931a",
      "aef947f485a34e91969e1e3ab52934f3",
      "600321263b984d8ea88226070e8bb6b4",
      "bdc457ea814643ea802a76ab52dc256c",
      "be2300e2205d4dbaa7c94db58037598e",
      "00a3d51de2554ed882581d04de559f74",
      "31fb51a053b944b0938fc25b436114b5",
      "63434fc028e247df98602bbf0663829d",
      "7647955e42434487900cfd270ebd7bc7",
      "2532653c59584123b656c34e4f49ba10",
      "9ee5facf9a2f47cc9463be6e89dc90ee",
      "80b278a6dce94941ac06e29f2cc5c526",
      "087ad839197448a289598a0a3eec821b",
      "2d74fc34478e400da153d2285536b9f1",
      "c457807095a24ee8b108db15f683305d",
      "e06f5e089d20450ea34f1530073993df",
      "3fdb255715c6487e8dedf6eb6b99175b",
      "5c280c8216ae47ea8891e69ce3505225",
      "406fdb980a754308a1817b596f344211",
      "5d5063b362414a08a5cb4ebf8037665a",
      "46d9fcc4e0b9463ab4168a8da7c2d89d",
      "1a29866936cf4798a8b98c7c4565bd8f",
      "4c03270facda4e22bdaf7b9406828b26",
      "facb757bc5254bbeb0303743d2f02950",
      "61a6d0c173c9429e80a631592a161774",
      "c858ba8c7e3e4dbead497c64fcab2db2",
      "dded1543d408448d8d8fc3708ec00d07",
      "0d4456aae37c422fa0de34d8c3ddb37d",
      "c8635366df5348fab4d84dcf00c7cca3",
      "7ef986cc364748e0968fa415368f8ec4",
      "0c4b5de1297d43bca67635221dd8e70d",
      "e5d252afce704061a3371378b35c0e4e",
      "33b73b4f3e894973a1ec812f1c6a4613",
      "c7ee80f74e804107af5d1193e670c394",
      "de3e3864b018423e8e3bc1b9b2fa37f3",
      "a3a16eed868f42408dc452642d690fd0",
      "b57b16eb3f724925b61f5756684399e1",
      "1253e2f70dce465ebfd7b12fc2714236",
      "08fe0a3c34c443d3aee30af2aae5bd03",
      "59da8399349443f08d697ff889e56143",
      "3d7441452fc24f678df33c5840fd4990",
      "c95cd8546340418aa523a5cd1ed8817a",
      "b7af5d6360cc4cf985a118ac595c4e1c",
      "eeda132259c84e40addfc9c678012481",
      "4d85e954dc7d4142a620135d7c8135f7",
      "fedb65bb0f7a4fdba2bce8c99d90c641",
      "7a8d39994d384faab859f2367f2fe154",
      "a1385b8374ab46d682a9f9b0739ffea4",
      "01f7c56e1ac1446896c8835807bd1301",
      "9c411859f48b4b8c8bf161b72f054b9a",
      "5b279ff0caf54b2588898069d042dcbb",
      "5722c065ee544c0a8c7fccf34e0f44b3",
      "5fb167363e444dc5b6ce6604bd6a3cd4",
      "8c9209f976174e4cace180347ff02c0c",
      "9f44a10225f6482c9121aaddf64c008c",
      "e2a57d57f35249c6a98ea5962bb20e7b",
      "f8d7fe66bbb34b899234204dfcd4fcb4",
      "4fb001e5f800463b81f567a9cb343cdc",
      "616bb9885b0442ec969e78a5da30a82d",
      "e84da5e403f5427b81221ff941034b36",
      "7f6bfbd974da4293ad2014ee1bfa51f0",
      "7e30fa3519f4496ead467d47cf4a539b",
      "217923ac64924cd2957167842508ee6b",
      "1ed709b53d3940dcaf4bea2900694c0d",
      "8cbca4aaf0d247a18de09bfadc443852",
      "7b44550736fd4b3394002305d2cfb975",
      "13655939af98425585334ba65ca5abb5",
      "2b768239923b4603966f67fd776313bc",
      "cef8fdb0232f4783a9038b95f2c0505a",
      "65c12608a72041cfb1260c9f9a22338d",
      "cf94fcbcc06046f89e5df6517cf11230",
      "cacb4b4915fb4580a037ddbf377722a2",
      "9ce7294f7aa44fea9586c6b2b3eedc06",
      "225fd46bd4ba403e96b3fc478e2810e8",
      "4c533ba51d1e499382d61e3658f49cb2",
      "30751fa55f604735a315718150035b16",
      "251ae4d97df04b4ab4463e766d82482e",
      "1d705f82508040f1a96eb961f6d4507c",
      "d7682ef1e59048e3883fd895acf13d22",
      "1fc4b9b89b534e6381d0a908944b3629",
      "c8a6b17361064b25844fd54426e177f0",
      "a83ecff288d745a68a610de6f8875f49",
      "90a48d02b15440918c52a8214bf80216",
      "1d289ea05a9c42fc98e1ef12bfee86c9"
     ]
    },
    "executionInfo": {
     "elapsed": 195552,
     "status": "ok",
     "timestamp": 1760030596612,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "vnxnv8WdR7sr",
    "outputId": "1d316705-ebd4-45b1-e26d-a9b2ed24af03"
   },
   "outputs": [],
   "source": [
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# トークナイザーの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    CFG.model_name,\n",
    "    trust_remote_code=True,\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760030596614,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Vb3n77IwR7sr"
   },
   "outputs": [],
   "source": [
    "def add_completion_token(\n",
    "        model: AutoModelForCausalLM,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        completions: list[str]\n",
    "    ) -> PreTrainedTokenizer:\n",
    "    special_tokens_dict = {\"additional_special_tokens\": completions}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    print(f\"Added {len(completions)} special tokens.\")\n",
    "\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f\"Resized model embeddings to {len(tokenizer)} tokens.\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 799,
     "status": "ok",
     "timestamp": 1760030597415,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "XQr9BrseR7sr",
    "outputId": "934ad4ec-adc4-4e0d-bb58-9f72da2f8159"
   },
   "outputs": [],
   "source": [
    "# 全てのラベルを保存\n",
    "with open(f\"{CFG.output_dir_path}/all_completions.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_completions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 全てのラベルを特殊トークンとして追加\n",
    "model, tokenizer = add_completion_token(model, tokenizer, all_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "executionInfo": {
     "elapsed": 5026,
     "status": "ok",
     "timestamp": 1760030602441,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "Xkr1qpKLR7sr",
    "outputId": "5cf88c53-b343-4a80-c34d-ef8572b598f7"
   },
   "outputs": [],
   "source": [
    "# wandbのログイン\n",
    "wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.init(project=CFG.comp_name, name=CFG.exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 594,
     "status": "ok",
     "timestamp": 1760030603036,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gH24xZA-R7sr"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat <<'EOT' > ds_config_zero1.json\n",
    "{\n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 16,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": \"auto\"\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 1,\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"none\",\n",
    "            \"pin_memory\": true\n",
    "        }\n",
    "    },\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 2000,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": false\n",
    "}\n",
    "EOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3999,
     "status": "ok",
     "timestamp": 1760030607041,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "J5OJ5ormR7sr"
   },
   "outputs": [],
   "source": [
    "# 学習の設定\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=CFG.output_dir_path,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=CFG.num_train_epochs,\n",
    "    per_device_train_batch_size=CFG.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=CFG.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=CFG.per_device_eval_batch_size,\n",
    "    learning_rate=CFG.learning_rate,\n",
    "    optim=CFG.optim_type,\n",
    "    lr_scheduler_type=CFG.lr_scheduler_type,\n",
    "    warmup_ratio=CFG.warmup_ratio,\n",
    "    weight_decay=CFG.weight_decay,\n",
    "    logging_dir=CFG.log_dir_path,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=10,\n",
    "    eval_steps=0.195,\n",
    "    max_length=CFG.max_len,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=\"wandb\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    bf16_full_eval=True,\n",
    "    gradient_checkpointing=False,\n",
    "    completion_only_loss=True,\n",
    "    deepspeed=\"ds_config_zero1.json\",\n",
    "    dataset_num_proc=8,\n",
    "    remove_unused_columns=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760030607053,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "nndt9wRoR7sr"
   },
   "outputs": [],
   "source": [
    "# 追加済みの全ラベルをIDに\n",
    "new_token_ids = tokenizer.convert_tokens_to_ids(all_completions)\n",
    "\n",
    "# LoRAの設定\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.lora_r,\n",
    "    lora_alpha=CFG.lora_alpha,\n",
    "    lora_dropout=CFG.lora_dropout,\n",
    "    bias=CFG.lora_bias,\n",
    "    target_modules=CFG.target_modules,\n",
    "    task_type=CFG.task_type,\n",
    "    modules_to_save=[\"lm_head\"],\n",
    "    trainable_token_indices={\"embed_tokens\": new_token_ids}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxALZ_PTR7sr"
   },
   "source": [
    "### カスタムトレーナー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1760030607054,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "QrBGkcslLvDj"
   },
   "outputs": [],
   "source": [
    "class SoftLabelCollator:\n",
    "    \"soft_labelsをcustom_trainerに渡す\"\n",
    "    def __init__(self, base_collator):\n",
    "        self.base_collator = base_collator\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        has_soft_labels = \"soft_labels\" in examples[0]\n",
    "        if has_soft_labels:\n",
    "            soft_labels = [ex[\"soft_labels\"] for ex in examples]\n",
    "        else:\n",
    "            soft_labels = None\n",
    "\n",
    "        # 既存のcollatorを通す\n",
    "        batch = self.base_collator(examples)\n",
    "\n",
    "        # soft_labels をそのまま追加\n",
    "        if has_soft_labels:\n",
    "            batch[\"soft_labels\"] = soft_labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1760030607087,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "gqOAqy-fz0KF"
   },
   "outputs": [],
   "source": [
    "class SoftLabelSFTTrainer(SFTTrainer):\n",
    "    \"\"\"ソフトラベル学習に対応したカスタムSFTTrainer\"\"\"\n",
    "\n",
    "    def __init__(self, temperature=1.0, alpha=0.7, category_token_ids=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.category_token_ids = (torch.tensor(category_token_ids) if category_token_ids else None)\n",
    "        self.kl_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"ソフトラベルとハードラベルの混合損失を計算\"\"\"\n",
    "\n",
    "        # ソフトラベル取得\n",
    "        soft_labels = inputs.pop(\"soft_labels\", None)\n",
    "\n",
    "        # 通常のforward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # ソフトラベルとカテゴリトークンが指定されている場合のみ特殊処理\n",
    "        # ------------------------------------------------------------\n",
    "        if soft_labels is not None and self.category_token_ids is not None:\n",
    "            labels = inputs.get(\"labels\", None)\n",
    "            if labels is None:\n",
    "                return outputs.loss if not return_outputs else (outputs.loss, outputs)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "            category_positions = []\n",
    "            actual_category_labels = []\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # カテゴリトークンの位置を特定し、予測すべき位置を抽出\n",
    "            # ------------------------------------------------------------\n",
    "            for b in range(batch_size):\n",
    "                sample_labels = labels[b]\n",
    "                cat_mask = torch.zeros_like(sample_labels, dtype=torch.bool)\n",
    "\n",
    "                for cat_id in self.category_token_ids:\n",
    "                    cat_mask |= (sample_labels == cat_id.to(sample_labels.device))\n",
    "\n",
    "                cat_positions = torch.nonzero(cat_mask, as_tuple=True)[0]\n",
    "\n",
    "                if len(cat_positions) > 0:\n",
    "                    # 最初のカテゴリトークンの1つ前を予測位置とする\n",
    "                    pos = max(cat_positions[0].item() - 1, 0)\n",
    "                    actual_category_labels.append(sample_labels[cat_positions[0]].item())\n",
    "                else:\n",
    "                    # カテゴリトークンが見つからない場合、最後の有効トークンを使う\n",
    "                    print(\"カテゴリトークンが見つかりません\")\n",
    "                    valid_mask = sample_labels != -100\n",
    "                    valid_positions = torch.nonzero(valid_mask, as_tuple=True)[0]\n",
    "                    if len(valid_positions) > 0:\n",
    "                        pos = valid_positions[-2].item() if len(valid_positions) > 1 else 0\n",
    "                        actual_category_labels.append(sample_labels[valid_positions[-1]].item())\n",
    "                    else:\n",
    "                        pos = logits.size(1) - 1\n",
    "                        actual_category_labels.append(-100)\n",
    "\n",
    "                category_positions.append(pos)\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 各サンプルの対象位置のlogitsを取得\n",
    "            # ------------------------------------------------------------\n",
    "            selected_logits = torch.stack([\n",
    "                logits[i, pos, :] for i, pos in enumerate(category_positions)\n",
    "            ])\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # デバッグ出力\n",
    "            # ------------------------------------------------------------\n",
    "            if self.state.global_step % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    print(f\"\\n{'='*80}\")\n",
    "                    print(f\"[Step {self.state.global_step}] Token predictions at completion position:\")\n",
    "\n",
    "                    for i in range(min(3, batch_size)):\n",
    "                        print(f\"\\n  Sample {i} (position={category_positions[i]}):\")\n",
    "\n",
    "                        # --- (1) 全語彙からのトップ5 ---\n",
    "                        all_probs = F.softmax(selected_logits[i], dim=-1)\n",
    "                        top5_probs, top5_indices = torch.topk(all_probs, k=5, dim=-1)\n",
    "\n",
    "                        print(\"    Top-5 from ALL vocabulary:\")\n",
    "                        for idx, prob in zip(top5_indices, top5_probs):\n",
    "                            token_id = idx.item()\n",
    "                            token_str = (\n",
    "                                self.processing_class.decode([token_id]).strip()\n",
    "                                if hasattr(self.processing_class, \"decode\")\n",
    "                                else f\"token_{token_id}\"\n",
    "                            )\n",
    "                            marker = \" [CAT]\" if token_id in self.category_token_ids else \"\"\n",
    "                            print(f\"      {token_str}: {prob:.4f}{marker}\")\n",
    "\n",
    "                        # --- (2) カテゴリトークンのみのトップ5 ---\n",
    "                        cat_logits = selected_logits[i][self.category_token_ids.to(selected_logits.device)]\n",
    "                        cat_probs = F.softmax(cat_logits, dim=-1)\n",
    "                        top5_cat_probs, top5_cat_indices = torch.topk(\n",
    "                            cat_probs, k=min(5, cat_probs.size(-1)), dim=-1\n",
    "                        )\n",
    "\n",
    "                        print(\"    Top-5 CATEGORY tokens (Model Prediction):\")\n",
    "                        for idx, prob in zip(top5_cat_indices, top5_cat_probs):\n",
    "                            token_id = self.category_token_ids[idx].item()\n",
    "                            token_str = (\n",
    "                                self.processing_class.decode([token_id]).strip()\n",
    "                                if hasattr(self.processing_class, \"decode\")\n",
    "                                else f\"cat_{token_id}\"\n",
    "                            )\n",
    "                            print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "                        # --- (3) ソフトラベルのトップ5 ---\n",
    "                        soft_label_tensor = torch.as_tensor(\n",
    "                            soft_labels[i], dtype=torch.float32\n",
    "                        )\n",
    "                        top5_soft_probs, top5_soft_indices = torch.topk(\n",
    "                            soft_label_tensor, k=min(5, len(soft_label_tensor))\n",
    "                        )\n",
    "\n",
    "                        print(\"    Top-5 SOFT LABELS (Target Distribution):\")\n",
    "                        for idx, prob in zip(top5_soft_indices, top5_soft_probs):\n",
    "                            token_id = self.category_token_ids[idx].item()\n",
    "                            token_str = (\n",
    "                                self.processing_class.decode([token_id]).strip()\n",
    "                                if hasattr(self.processing_class, \"decode\")\n",
    "                                else f\"soft_{token_id}\"\n",
    "                            )\n",
    "                            print(f\"      {token_str}: {prob:.4f}\")\n",
    "\n",
    "                        # --- (4) 正解ラベルを表示 ---\n",
    "                        if i < len(actual_category_labels) and actual_category_labels[i] != -100:\n",
    "                            true_label_id = actual_category_labels[i]\n",
    "                            true_label_str = (\n",
    "                                self.processing_class.decode([true_label_id]).strip()\n",
    "                                if hasattr(self.processing_class, \"decode\")\n",
    "                                else f\"label_{true_label_id}\"\n",
    "                            )\n",
    "\n",
    "                            if true_label_id in self.category_token_ids:\n",
    "                                cat_index = (self.category_token_ids == true_label_id).nonzero(as_tuple=True)[0]\n",
    "                                if len(cat_index) > 0:\n",
    "                                    true_prob = cat_probs[cat_index[0]].item()\n",
    "                                    print(f\"    TRUE LABEL: {true_label_str} (prob={true_prob:.4f})\")\n",
    "                                else:\n",
    "                                    print(f\"    TRUE LABEL: {true_label_str}\")\n",
    "                            else:\n",
    "                                print(f\"    TRUE LABEL: {true_label_str} [NOT A CATEGORY TOKEN]\")\n",
    "                        else:\n",
    "                            print(\"    TRUE LABEL: Not found\")\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # ソフトラベル損失（KL Divergence）の計算\n",
    "            # ------------------------------------------------------------\n",
    "            category_logits = selected_logits[:, self.category_token_ids.to(selected_logits.device)]\n",
    "            category_logits = category_logits / self.temperature\n",
    "            log_probs = F.log_softmax(category_logits, dim=-1)\n",
    "\n",
    "            soft_labels_tensor = torch.stack([\n",
    "                torch.as_tensor(sl, dtype=torch.float32) for sl in soft_labels\n",
    "            ]).to(log_probs.device)\n",
    "\n",
    "            # nn.KLDivLossを使用\n",
    "            kl_loss = self.kl_criterion(log_probs, soft_labels_tensor)\n",
    "            kl_loss *= self.temperature ** 2\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # 損失の混合\n",
    "            # ------------------------------------------------------------\n",
    "            hard_loss = outputs.loss if outputs.loss is not None else 0\n",
    "            total_loss = (1 - self.alpha) * hard_loss + self.alpha * kl_loss\n",
    "\n",
    "            if self.state.global_step % 50 == 0:\n",
    "                print(f\"\\n  Losses - Hard: {hard_loss.item():.4f}, KL: {kl_loss.item():.4f}, Total: {total_loss.item():.4f}\")\n",
    "                print('=' * 80)\n",
    "\n",
    "        else:\n",
    "            # ソフトラベルを使用しない通常損失\n",
    "            total_loss = outputs.loss\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhVu51fNULHR"
   },
   "source": [
    "### 評価関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030607093,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "LAxhktY2UKHP"
   },
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"logitsから上位5件のトークンIDを抽出\"\"\"\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "\n",
    "    # top-kの値とインデックスを取得\n",
    "    k = 5\n",
    "    _, topk_indices = torch.topk(\n",
    "        logits,\n",
    "        k=min(k, logits.size(-1)),\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True\n",
    "    )\n",
    "\n",
    "    return topk_indices, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760030607101,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "1ArxPkjxUKJz"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    \"\"\"メトリクス（accuracy と MAP@3）を計算する関数。\"\"\"\n",
    "    topk_preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(topk_preds, tuple):\n",
    "        topk_preds = topk_preds[0]\n",
    "\n",
    "    # -100 と eos を無視\n",
    "    ignore_ids = {-100, eos_token_id}\n",
    "    valid_labels_mask = ~np.isin(labels, list(ignore_ids))\n",
    "    valid_labels = labels[valid_labels_mask]\n",
    "\n",
    "    # preds とラベルを位置合わせ（1トークンずれ対策）\n",
    "    shifted_mask = np.roll(valid_labels_mask, shift=-1, axis=1)\n",
    "    shifted_mask[:, -1] = False\n",
    "    aligned_topk_preds = topk_preds[shifted_mask]  # shape: (N, topk)\n",
    "\n",
    "    # デコード\n",
    "    decoded_topk_preds = [\n",
    "        [tokenizer.decode([int(pred)]) for pred in preds_topk]\n",
    "        for preds_topk in aligned_topk_preds\n",
    "    ]\n",
    "    decoded_labels = [tokenizer.decode([int(label)]) for label in valid_labels]\n",
    "\n",
    "    # accuracy\n",
    "    accuracy = np.mean([\n",
    "        preds_topk[0].strip() == label.strip()\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    # MAP@3\n",
    "    map3 = np.mean([\n",
    "        sum((label.strip() == pred.strip()) / (rank+1)\n",
    "            for rank, pred in enumerate(preds_topk))\n",
    "        for preds_topk, label in zip(decoded_topk_preds, decoded_labels)\n",
    "    ])\n",
    "\n",
    "    return {\"accuracy\": float(accuracy), \"map@3\": float(map3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO2rpJN6Us3V"
   },
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1760030607109,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "SX2rWXZ_Q6TZ"
   },
   "outputs": [],
   "source": [
    "# collatorの定義\n",
    "base = DataCollatorForLanguageModeling(\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    completion_only_loss=True,\n",
    "    padding_free=False\n",
    ")\n",
    "collator = SoftLabelCollator(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "35437af906e04082a3f10ce00eee73c8",
      "4a8ec9649a3841dbbd68accae024887f",
      "faa0c462450e43eca80a2eb86a85dcf0",
      "24af1965e9214a46be1484e1bbbdce9f",
      "08019dce37da427ea075e971560d8e1d",
      "31a39be43e714653b86e3b95b98c4261",
      "80342a95b389414eba29673da62b729a",
      "4194016de9ea494093a7ed6b2c5d53cb",
      "1c0cbe53252e416ca5835db3d1c419e0",
      "249892fadf2f4799aec7080698ee7fa9",
      "18d10d98162e411b87c7729ab6150c4f",
      "e54418763c084a338bdc5eb2df253687",
      "35402b0d3c31401abb124638695fa17d",
      "19e4060b995b4f66892580f5221874ff",
      "5ee4b1266c904a129597fc494b0e86d7",
      "0765e9ea71b445c19a596732870ada8f",
      "131b2ef36c564f46a6ae0eaed1a987a8",
      "224a4bdf8c31426ea1db793e78f0be14",
      "403cb5d332fe4769989014bae89b9d57",
      "61afd1eaa29048e2bda4a559e7c33f1f",
      "c06df48ca626447591c4f7fd27473626",
      "9206eb92656842dd9c10556c72b88027",
      "7a015c3dae6b4d94a49524643ed07c29",
      "b14c9d9597834bf9bd5e99deb8a6dbdb",
      "36727ad6cf274e49a01c926d8ba6bc0d",
      "6fb566fe29f545a695e0cea34a5c484d",
      "3eb14f10dda34688ae51b61b92f2df47",
      "6ca8e6d131d24b5c86e06c7f5920203e",
      "7fef961cddf741e4adb01a834348e0b5",
      "464ff738221d43b58b988fbfe0091e97",
      "23a1b0c03e4e48ef9b1620689cea75fe",
      "27f8682516b24edfb9ac039eba0c157a",
      "c7ced8fb9f324fe588401aa5cb52dbc5",
      "8c45d847a8fc41619d6c75a8d17ffe90",
      "79b5cdda31c648bd959726618aac8701",
      "98172011f36444618e30de6864376365",
      "0b850567c70344f2a8e117c165a7e3dc",
      "eb3634aac57045748c6ed7a562c4814f",
      "37b3f8d38ba947c5a2fa08270b5af3fe",
      "056ba13efe824086899658ea86a877ab",
      "de99d0a027c244bf8b0677876af41359",
      "96ee7e7b744f4d34b320ab86d769411a",
      "817cdab2dea442c8bfd345e64b5e7fb4",
      "ed959d0634ff43ae94de640a14f69b9b",
      "59095133ae9747b68e8c308aef572b84",
      "83ed4bf9a8b34a25906e9066650c1d2a",
      "b6eebdb5427745bd887f4a8ec1904f6b",
      "5456dbdf00164c91a28e0fa4298ac823",
      "0fb53689ec40435d9cdfcc6ed0a9e1a5",
      "492264ce798f4dbeaef8cb20f582c1b5",
      "a29b3869c2b34d5cbab62f0a7fc4a174",
      "c7b17f0cd33e42f999bc35c844ca56d0",
      "9c3ead1eb06e4582a97b5343961d62c1",
      "eda7082ee8cf49d9bf128ce8616392a2",
      "dc0937741e874a268b32c115ea7b1672",
      "1a8079690c824eccb8c50d41e51e1863",
      "9fd3d32bf32b4222b373cbca3cb725ea",
      "ed40895ebb104346afee49b4925a1978",
      "79d6cf17066f4e1981cc4b20b952eb76",
      "b975132c40f74a6a9039df295902e3c0",
      "90134aebe78249888f5e7974a3d4beb1",
      "09f7c10bcc2b45ae84123f78809bde25",
      "e6fffc6db3394c8db059ee5fdc35d7a2",
      "5ddc334b165a40e782e2ac812d09ff20",
      "aeb07f059bfe40a58e289f3799e5eba4",
      "bfa64fcae927468a82b688569a13f2d4"
     ]
    },
    "executionInfo": {
     "elapsed": 24784,
     "status": "ok",
     "timestamp": 1760030631893,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "OQEbDmC2Q6Vv",
    "outputId": "46cd28c4-e930-414d-e22d-ad0aed129c3b"
   },
   "outputs": [],
   "source": [
    "# カスタムトレーナーの設定\n",
    "trainer = SoftLabelSFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=lora_config,\n",
    "    temperature=CFG.temperature,\n",
    "    alpha=CFG.alpha,\n",
    "    category_token_ids=new_token_ids,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collator,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1760030631914,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "bq4-w21RQ6a5",
    "outputId": "aa83826b-3fae-432c-f964-95183d484021"
   },
   "outputs": [],
   "source": [
    "for n, p in trainer.model.named_parameters():\n",
    "    if \"embed_tokens\" in n or \"lm_head\" in n:\n",
    "        print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 48958,
     "status": "error",
     "timestamp": 1760030680872,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "z7q9rQZSMjc8",
    "outputId": "e5c2b173-b2af-407e-d983-cfa72aa536dd"
   },
   "outputs": [],
   "source": [
    "# 学習\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "aborted",
     "timestamp": 1760030680891,
     "user": {
      "displayName": "力岡友和",
      "userId": "08962514836758233245"
     },
     "user_tz": -540
    },
    "id": "7-RAYBcPR7ss"
   },
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "trainer.save_model(CFG.output_dir_path + \"/model\")\n",
    "tokenizer.save_pretrained(CFG.output_dir_path + \"/model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
